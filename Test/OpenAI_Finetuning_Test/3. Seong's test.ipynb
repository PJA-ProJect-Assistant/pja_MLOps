{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb641fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce2a09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>total_requirements</th>\n",
       "      <th>project_info</th>\n",
       "      <th>ERD_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'projectName': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', 'projectTa...</td>\n",
       "      <td>[{'requirementType': 'FUNCTIONAL', 'content': ...</td>\n",
       "      <td>{'project_info': {'title': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', ...</td>\n",
       "      <td>{'erd_tables': [{'name': 'users', 'erd_columns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'projectName': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'projectTarget': 'ì¹˜...</td>\n",
       "      <td>[{'requirementType': 'FUNCTIONAL', 'content': ...</td>\n",
       "      <td>{'project_info': {'title': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'category...</td>\n",
       "      <td>{'erd_tables': [{'name': 'Users', 'erd_columns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'projectName': 'ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±', 'projectT...</td>\n",
       "      <td>[{'requirementType': 'FUNCTIONAL', 'content': ...</td>\n",
       "      <td>{'project_info': {'title': 'ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±',...</td>\n",
       "      <td>{'erd_tables': [{'name': 'Users', 'erd_columns...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  [{'projectName': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', 'projectTa...   \n",
       "1  [{'projectName': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'projectTarget': 'ì¹˜...   \n",
       "2  [{'projectName': 'ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±', 'projectT...   \n",
       "\n",
       "                                  total_requirements  \\\n",
       "0  [{'requirementType': 'FUNCTIONAL', 'content': ...   \n",
       "1  [{'requirementType': 'FUNCTIONAL', 'content': ...   \n",
       "2  [{'requirementType': 'FUNCTIONAL', 'content': ...   \n",
       "\n",
       "                                        project_info  \\\n",
       "0  {'project_info': {'title': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', ...   \n",
       "1  {'project_info': {'title': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'category...   \n",
       "2  {'project_info': {'title': 'ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±',...   \n",
       "\n",
       "                                            ERD_data  \n",
       "0  {'erd_tables': [{'name': 'users', 'erd_columns...  \n",
       "1  {'erd_tables': [{'name': 'Users', 'erd_columns...  \n",
       "2  {'erd_tables': [{'name': 'Users', 'erd_columns...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv(\"hehe.csv\")\n",
    "df.head(3)  # ì•ë¶€ë¶„ë§Œ ë¯¸ë¦¬ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d55e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_field(field):\n",
    "    \"\"\"ë¬¸ìì—´ë¡œ ì €ì¥ëœ dict/listë¥¼ ì‹¤ì œ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜\"\"\"\n",
    "    try:\n",
    "        return str(ast.literal_eval(field))\n",
    "    except Exception as e:\n",
    "        print(\"ë³€í™˜ ì˜¤ë¥˜:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a305f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://3.34.185.3:8000/\"\n",
    "\n",
    "def ERD_generate(user_info, requirement, project_info):\n",
    "    data = {\n",
    "        \"project_overview\": user_info,\n",
    "        \"requirements\": requirement,\n",
    "        \"project_summury\": project_info,\n",
    "        \"max_tokens\": 4000,\n",
    "        \"temperature\": 0.3,\n",
    "        \"model\": \"gpt-4o\"\n",
    "    }\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.post(\n",
    "            url = base_url + \"api/PJA/json_ERD/generate\",\n",
    "            json = data,\n",
    "            headers= {\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        return response.json().get('json', None), elapsed\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"ERD_generate error:\", e)\n",
    "        return None, None\n",
    "\n",
    "def new_ERD_generate(user_info, requirement, project_info):\n",
    "    data = {\n",
    "        \"project_overview\": user_info,\n",
    "        \"requirements\": requirement,\n",
    "        \"project_summury\": project_info,\n",
    "        \"max_tokens\": 4000,\n",
    "        \"temperature\": 0.3,\n",
    "        \"model\": \"ft:gpt-4o-mini-2024-07-18:test:pja-erd-finetuning-model:BmOgyl6o\"\n",
    "    }\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.post(\n",
    "            url = base_url + \"api/PJA/json_ERD/generate\",\n",
    "            json = data,\n",
    "            headers= {\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        return response.json().get('json', None), elapsed\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"new_ERD_generate error:\", e)\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64cd2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4o ERD ê²°ê³¼: {'erd_tables': [{'name': 'users', 'erd_columns': [{'name': 'user_id', 'data_type': 'serial', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'email', 'data_type': 'varchar(255)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'password', 'data_type': 'varchar(255)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'name', 'data_type': 'varchar(255)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'email_verified', 'data_type': 'boolean', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}]}, {'name': 'study_groups', 'erd_columns': [{'name': 'group_id', 'data_type': 'serial', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'group_name', 'data_type': 'varchar(255)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'created_by', 'data_type': 'integer', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}]}, {'name': 'quizzes', 'erd_columns': [{'name': 'quiz_id', 'data_type': 'serial', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'group_id', 'data_type': 'integer', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}, {'name': 'quiz_name', 'data_type': 'varchar(255)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}]}, {'name': 'announcements', 'erd_columns': [{'name': 'announcement_id', 'data_type': 'serial', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'group_id', 'data_type': 'integer', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}, {'name': 'content', 'data_type': 'text', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'created_by', 'data_type': 'integer', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}]}, {'name': 'study_materials', 'erd_columns': [{'name': 'material_id', 'data_type': 'serial', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'group_id', 'data_type': 'integer', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}, {'name': 'file_name', 'data_type': 'varchar(255)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'uploaded_by', 'data_type': 'integer', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}]}], 'erd_relationships': [{'from_table': 'study_groups', 'to_table': 'users', 'relationship_type': 'one-to-many', 'foreign_key': 'created_by', 'constraint_name': 'fk_study_groups_users'}, {'from_table': 'quizzes', 'to_table': 'study_groups', 'relationship_type': 'one-to-many', 'foreign_key': 'group_id', 'constraint_name': 'fk_quizzes_study_groups'}, {'from_table': 'announcements', 'to_table': 'study_groups', 'relationship_type': 'one-to-many', 'foreign_key': 'group_id', 'constraint_name': 'fk_announcements_study_groups'}, {'from_table': 'announcements', 'to_table': 'users', 'relationship_type': 'many-to-one', 'foreign_key': 'created_by', 'constraint_name': 'fk_announcements_users'}, {'from_table': 'study_materials', 'to_table': 'study_groups', 'relationship_type': 'one-to-many', 'foreign_key': 'group_id', 'constraint_name': 'fk_study_materials_study_groups'}, {'from_table': 'study_materials', 'to_table': 'users', 'relationship_type': 'many-to-one', 'foreign_key': 'uploaded_by', 'constraint_name': 'fk_study_materials_users'}]}\n",
      "GPT-4o ì‘ë‹µì‹œê°„: 17.7692232131958 ì´ˆ\n",
      "Fine-tuned GPT-4o-mini ERD ê²°ê³¼: {'erd_tables': [{'name': 'ì‚¬ìš©ì', 'erd_columns': [{'name': 'ì‚¬ìš©ìID', 'data_type': 'INTEGER', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'ì´ë©”ì¼', 'data_type': 'VARCHAR', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'ë¹„ë°€ë²ˆí˜¸', 'data_type': 'VARCHAR', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}]}, {'name': 'ìŠ¤í„°ë”” ê·¸ë£¹', 'erd_columns': [{'name': 'ìŠ¤í„°ë””ID', 'data_type': 'INTEGER', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'ìŠ¤í„°ë””ëª…', 'data_type': 'VARCHAR', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'ê´€ë¦¬ìID', 'data_type': 'INTEGER', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}]}, {'name': 'í€´ì¦ˆ', 'erd_columns': [{'name': 'í€´ì¦ˆID', 'data_type': 'INTEGER', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'ì œëª©', 'data_type': 'VARCHAR', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'ìŠ¤í„°ë””ID', 'data_type': 'INTEGER', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}]}, {'name': 'ê³µì§€ì‚¬í•­', 'erd_columns': [{'name': 'ê³µì§€ID', 'data_type': 'INTEGER', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'ë‚´ìš©', 'data_type': 'TEXT', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'ìŠ¤í„°ë””ID', 'data_type': 'INTEGER', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}]}, {'name': 'í•™ìŠµ ìë£Œ', 'erd_columns': [{'name': 'ìë£ŒID', 'data_type': 'INTEGER', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'íŒŒì¼ëª…', 'data_type': 'VARCHAR', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'ìŠ¤í„°ë””ID', 'data_type': 'INTEGER', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}]}], 'erd_relationships': [{'from_table': 'ì‚¬ìš©ì', 'to_table': 'ìŠ¤í„°ë”” ê·¸ë£¹', 'relationship_type': 'one-to-many', 'foreign_key': 'ê´€ë¦¬ìID', 'constraint_name': 'fk_ì‚¬ìš©ì_ìŠ¤í„°ë””ê·¸ë£¹'}, {'from_table': 'ìŠ¤í„°ë”” ê·¸ë£¹', 'to_table': 'í€´ì¦ˆ', 'relationship_type': 'one-to-many', 'foreign_key': 'ìŠ¤í„°ë””ID', 'constraint_name': 'fk_ìŠ¤í„°ë””ê·¸ë£¹_í€´ì¦ˆ'}, {'from_table': 'ìŠ¤í„°ë”” ê·¸ë£¹', 'to_table': 'ê³µì§€ì‚¬í•­', 'relationship_type': 'one-to-many', 'foreign_key': 'ìŠ¤í„°ë””ID', 'constraint_name': 'fk_ìŠ¤í„°ë””ê·¸ë£¹_ê³µì§€ì‚¬í•­'}, {'from_table': 'ìŠ¤í„°ë”” ê·¸ë£¹', 'to_table': 'í•™ìŠµ ìë£Œ', 'relationship_type': 'one-to-many', 'foreign_key': 'ìŠ¤í„°ë””ID', 'constraint_name': 'fk_ìŠ¤í„°ë””ê·¸ë£¹_í•™ìŠµìë£Œ'}]}\n",
      "Fine-tuned ì‘ë‹µì‹œê°„: 13.895011901855469 ì´ˆ\n"
     ]
    }
   ],
   "source": [
    "# 0ë²ˆ(ì²« ë²ˆì§¸) í”„ë¡œì íŠ¸ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸\n",
    "row = df.iloc[0]\n",
    "user_input = parse_field(row['user_input'])\n",
    "requirements = parse_field(row['total_requirements'])\n",
    "project_info = parse_field(row['project_info'])\n",
    "\n",
    "# ê¸°ë³¸ ëª¨ë¸ ERD\n",
    "erd1, time1 = ERD_generate(user_input, requirements, project_info)\n",
    "print(\"GPT-4o ERD ê²°ê³¼:\", erd1)\n",
    "print(\"GPT-4o ì‘ë‹µì‹œê°„:\", time1, \"ì´ˆ\")\n",
    "\n",
    "# íŒŒì¸íŠœë‹ ëª¨ë¸ ERD\n",
    "erd2, time2 = new_ERD_generate(user_input, requirements, project_info)\n",
    "print(\"Fine-tuned GPT-4o-mini ERD ê²°ê³¼:\", erd2)\n",
    "print(\"Fine-tuned ì‘ë‹µì‹œê°„:\", time2, \"ì´ˆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b1a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬ ì™„ë£Œ\n",
      "[2] ê¸°ì–µì˜ ë‹¤ë¦¬ ì™„ë£Œ\n",
      "[3] ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•± ì™„ë£Œ\n",
      "[4] ê°€ìƒ í”¼íŒ…ë£¸ ì„œë¹„ìŠ¤ ì™„ë£Œ\n",
      "[5] ìŠ¤ë§ˆíŠ¸ ê±´ê°• ê´€ë¦¬ ë¹„ì„œ ì™„ë£Œ\n",
      "[6] ê·¸ë¦° ì±Œë¦°ì§€ ì™„ë£Œ\n",
      "[7] ìŠ¤ë§ˆíŠ¸ í•™ìŠµ ê¸°ë¡ ê´€ë¦¬ì ì™„ë£Œ\n",
      "[8] ìŠ¤ë§ˆíŠ¸ ì˜ì–‘ì†Œ ë¶„ì„ê¸° ì™„ë£Œ\n",
      "[9] ê°ì • ê¸°ë¡ ë§¤ë‹ˆì € ì™„ë£Œ\n",
      "[10] ì¬ë¬´ê´€ë¦¬ ë„ìš°ë¯¸(Financial Buddy) ì™„ë£Œ\n",
      "[11] ê²°í˜¼ ì¤€ë¹„ ë„ìš°ë¯¸ ì™„ë£Œ\n",
      "[12] ì¤‘ê³  ë¬¼í’ˆ ëŒ€ì—¬ ë§¤ì¹­ í”Œë«í¼ ì™„ë£Œ\n",
      "[13] EcoSense: ì‹¤ì‹œê°„ í™˜ê²½ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[14] ìŠ¤ë§ˆíŠ¸ ê³µê¸°ì§ˆ ë¶„ì„ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[15] ë¹„ì ‘ì´‰ì‹ ê°ì • ì¸ì‹ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[16] ìŠ¤ë§ˆíŠ¸ ê³µê¸°ì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[17] í•„ì²´ ìŠ¤íƒ€ì¼ ë³€í™˜ê¸° ì™„ë£Œ\n",
      "[18] ìŠ¤ë§ˆíŠ¸ ì—ë„ˆì§€ ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[19] ì† ì œìŠ¤ì²˜ ê¸°ë°˜ ê¸ˆìœµ ë³´ì•ˆ ì¸ì¦ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[20] Smart Consumer Insight Platform ì™„ë£Œ\n",
      "[21] ì‹¤ì‹œê°„ ì†Œë¹„ì ì˜ê²¬ ë¶„ì„ í”Œë«í¼ ì™„ë£Œ\n",
      "[22] ìŠ¤ë§ˆíŠ¸ êµí†µ ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[23] ìŠ¤ë§ˆíŠ¸ ì‹¤ë‚´ ê³µê¸° ì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[24] ì•½ ë³µìš© ë¦¬ë§ˆì¸ë” ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[25] ìŠ¤ë§ˆíŠ¸ í”¼íŠ¸ë‹ˆìŠ¤ ì½”ì¹˜ ì™„ë£Œ\n",
      "[26] ìŠ¤ë§ˆíŠ¸ ìŒì„± ì•ˆë‚´ ë‚´ë¹„ê²Œì´ì…˜ ì™„ë£Œ\n",
      "[27] ì¶œì¥ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ í”Œë«í¼ ì™„ë£Œ\n",
      "[28] ì¶•ì œ ë°©ë¬¸ì íë¦„ ìµœì í™” ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[29] ì „í†µì‹œì¥ ìŠ¤ë§ˆíŠ¸ ì¬ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[30] ìŠ¤ë§ˆíŠ¸ ì¶œê²° ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[31] ìŠ¤ë§ˆíŠ¸ ì—ë„ˆì§€ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[32] UrbanGreen Monitor ì™„ë£Œ\n",
      "[33] BookClub ì™„ë£Œ\n",
      "[34] ExpenseAnalyzer ì™„ë£Œ\n",
      "[35] MealPrepMaster ì™„ë£Œ\n",
      "[36] EcoTrack ì™„ë£Œ\n",
      "[37] ê·¸ë¦° ì¼€ì–´: ìŠ¤ë§ˆíŠ¸ ì‹ë¬¼ ê´€ë¦¬ ì†”ë£¨ì…˜ ì™„ë£Œ\n",
      "[38] SmartTask ë„ìš°ë¯¸ ì™„ë£Œ\n",
      "[39] ë¦¬ë·°ë¶ ì»¤ë®¤ë‹ˆí‹° ì™„ë£Œ\n",
      "[40] StudyTracker ì™„ë£Œ\n",
      "[41] ìŠ¤ë§ˆíŠ¸í•™ìŠµê´€ë¦¬ ì™„ë£Œ\n",
      "[42] ìŠ¤ë§ˆíŠ¸ ë†ì—… ë¶„ì„ê¸° ì™„ë£Œ\n",
      "[43] TeamSync ì™„ë£Œ\n",
      "[44] ë¦¬ë·° ì§„ìœ„ í™•ì¸ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[45] MedSchedule ì™„ë£Œ\n",
      "[46] AI ê³ ê° í”¼ë“œë°± ë¶„ì„ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[47] RecipeCollaborator ì™„ë£Œ\n",
      "[48] ê°œì¸í™” í•™ìŠµ ê²½í—˜ ê°œì„ ê¸° ì™„ë£Œ\n",
      "[49] ìŠ¤ë§ˆíŠ¸ í•™ìƒ ì„±ì  ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[50] ìŠ¤ë§ˆíŠ¸ ì¼ì • ì¡°ì •ê¸° ì™„ë£Œ\n",
      "[51] ìŠ¤ë§ˆíŠ¸ í•™ìŠµ ê³„íš ë„êµ¬ ì™„ë£Œ\n",
      "[52] TeamSync í”„ë¡œì íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[53] ìŠ¤ë§ˆíŠ¸ ì—ë„ˆì§€ ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[54] TeamSync ì™„ë£Œ\n",
      "[55] AgriConnect ì™„ë£Œ\n",
      "[56] StudySphere ì™„ë£Œ\n",
      "[57] í—¤ë¥´ë„: ë‹¤êµ­ì–´ í˜‘ì—… í”Œë«í¼ ì™„ë£Œ\n",
      "[58] NutriTrack ì™„ë£Œ\n",
      "[59] HabitTracker ì™„ë£Œ\n",
      "[60] LocalFarmConnect ì™„ë£Œ\n",
      "[61] TaskSync ì™„ë£Œ\n",
      "[62] Ad Performance Analyzer ì™„ë£Œ\n",
      "[63] LocalEventHub ì™„ë£Œ\n",
      "[64] ëˆ„ê°€ë‚˜ íŒŒí¬Park ì™„ë£Œ\n",
      "[65] GreenWaste Tracker ì™„ë£Œ\n",
      "[66] ê°œì¸ ë§ì¶¤í˜• í•™ìŠµ ê²½ë¡œ ì„¤ê³„ê¸° ì™„ë£Œ\n",
      "[67] TeamConnect ì™„ë£Œ\n",
      "[68] ì—´ì°¨ ì—¬í–‰ ë§ˆìŠ¤í„° ì™„ë£Œ\n",
      "[69] SmartRecipe ì™„ë£Œ\n",
      "[70] DeliveryScheduler ì™„ë£Œ\n",
      "[71] EcoChallenge ì™„ë£Œ\n",
      "[72] EcoTrack ì•± ì™„ë£Œ\n",
      "[73] HabitSync ì™„ë£Œ\n",
      "[74] SleepTrack ì™„ë£Œ\n",
      "[75] MealPlanPro ì™„ë£Œ\n",
      "[76] E-ë§¤ë„ˆìŠ¤: ì˜¨ë¼ì¸ íšŒì˜ ì—í‹°ì¼“ êµìœ¡ í”Œë«í¼ ì™„ë£Œ\n",
      "[77] TravelBuddy ì¼ì • ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[78] SmartRecipe ì™„ë£Œ\n",
      "[79] í˜‘ë ¥ ì—…ì²´ í‰ê°€ ë° ë¹„êµ í”Œë«í¼ ì™„ë£Œ\n",
      "[80] WeatherAlert ì•± ì™„ë£Œ\n",
      "[81] ë°˜ë ¤ê²¬ ì…ì–‘ ë§¤ì¹­ í”Œë«í¼ ì™„ë£Œ\n",
      "[82] CafeOrderSync ì™„ë£Œ\n",
      "[83] PriceWatch ì™„ë£Œ\n",
      "[84] GroupLearn ì™„ë£Œ\n",
      "[85] StockMaster ì™„ë£Œ\n",
      "[86] LearnWise ì™„ë£Œ\n",
      "[87] SmartDocSys ì™„ë£Œ\n",
      "[88] FreshTrack ì™„ë£Œ\n",
      "[89] TableTracker ì™„ë£Œ\n",
      "[90] í—¬ìŠ¤ íŠ¸ë˜ì»¤ ì»¤ë®¤ë‹ˆí‹° ì™„ë£Œ\n",
      "[91] ì•ˆì „í•œ ì¤‘ê³  ê±°ë˜ ë³´ì¡° í”Œë«í¼ ì™„ë£Œ\n",
      "[92] ëª…í’ˆ ì¸ì¦ ë° ê±°ë˜ í”Œë«í¼ ì™„ë£Œ\n",
      "[93] Festive Planner ì™„ë£Œ\n",
      "[94] íˆ¬ë‘ ìº˜ë¦°ë” ë§ˆìŠ¤í„° ì™„ë£Œ\n",
      "[95] PetCare Tracker ì™„ë£Œ\n",
      "[96] LearnTrack ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[97] ì—°ì°¸ í”„ë¡œì íŠ¸ Management ì™„ë£Œ\n",
      "[98] TeamSync ì™„ë£Œ\n",
      "[99] ì–¸ì–´ êµí™˜ ë„¤íŠ¸ì›Œí¬ ì™„ë£Œ\n",
      "[100] LightOptimizer ì™„ë£Œ\n",
      "[101] EcoShopper ì™„ë£Œ\n",
      "[102] Book Review Aggregator ì™„ë£Œ\n",
      "[103] íŒ€ í˜‘ì—… ë° í”¼ë“œë°± í”Œë«í¼ ì™„ë£Œ\n",
      "[104] íŒ€ì›Œí¬ í”ŒëŸ¬ìŠ¤: ê°€ìƒ íŒ€ í”„ë¡œì íŠ¸ ê´€ë¦¬ ë„êµ¬ ì™„ë£Œ\n",
      "[105] StudyBuddy ë©˜í† ë§ í”Œë«í¼ ì™„ë£Œ\n",
      "[106] ìŠ¤ë§ˆíŠ¸ ì•½ë¬¼ ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[107] BookCircle ì™„ë£Œ\n",
      "[108] CodeReviewEnhancer ì™„ë£Œ\n",
      "[109] MeetingOptimizer ì™„ë£Œ\n",
      "[110] BookTrade ì™„ë£Œ\n",
      "[111] íŒ€ì›Œí¬(TeamWork) ì™„ë£Œ\n",
      "[112] ìŠ¤ë§ˆíŠ¸ í†µê·¼ ìµœì í™” í”Œë«í¼ ì™„ë£Œ\n",
      "[113] FocusPlan ì™„ë£Œ\n",
      "[114] RecyClean ì™„ë£Œ\n",
      "[115] íƒ€ì„ ë§ˆìŠ¤í„° ì™„ë£Œ\n",
      "[116] EcoTracker ì™„ë£Œ\n",
      "[117] ScheduleSync ì™„ë£Œ\n",
      "[118] íŒ€ í˜‘ì—… ê´€ë¦¬ í”Œë«í¼ ì™„ë£Œ\n",
      "[119] ë‰´ìŠ¤ íë ˆì´í„°: ë§ì¶¤í˜• ë‰´ìŠ¤ ì•Œë¦¼ ì„œë¹„ìŠ¤ ì™„ë£Œ\n",
      "[120] íë ˆì´ë“œ(CURADE) - ê°œì¸í™”ëœ ì½˜í…ì¸  íë ˆì´ì…˜ í”Œë«í¼ ì™„ë£Œ\n",
      "[121] StockTrack Pro ì™„ë£Œ\n",
      "[122] Local Food Share í”Œë«í¼ ì™„ë£Œ\n",
      "[123] ìŠ¤í„°ë”” ê·¸ë£¹ ê´€ë¦¬ ì‹œìŠ¤í…œ ì™„ë£Œ\n",
      "[124] ìŠ¤ë§ˆíŠ¸ ë ˆì‹œí”¼ ë§¤ë‹ˆì € ì™„ë£Œ\n",
      "[125] ê°€ì¡± ì¼ì • ê³µìœ  ì•± ì™„ë£Œ\n",
      "[126] TaskCollab ì™„ë£Œ\n",
      "[127] SmartScheduler ì™„ë£Œ\n",
      "[128] ì ì‹¬ 360 ì™„ë£Œ\n",
      "[129] ì†Œë¹„ íŒ¨í„´ ë¶„ì„ê¸° ì™„ë£Œ\n",
      "[130] ìŠ¤ë§ˆíŠ¸ ìƒì‚°ì„± ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì™„ë£Œ\n",
      "[131] StudyTracker ì™„ë£Œ\n",
      "[132] TeamSync ì—…ë¬´ ê´€ë¦¬ í”Œë«í¼ ì™„ë£Œ\n",
      "[133] FocusMind ì•± ì™„ë£Œ\n",
      "[134] PersonaInsight ì™„ë£Œ\n",
      "[135] EcoTrack ì™„ë£Œ\n",
      "[136] ìŠ¤í„°ë”” ë§¤ë‹ˆì € ì™„ë£Œ\n",
      "[137] ë””ì§€í„¸ ê´€ë¦¬ ì½”ì¹˜ ì™„ë£Œ\n",
      "[138] LearnBuddy ì™„ë£Œ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_title</th>\n",
       "      <th>gpt-4o_erd</th>\n",
       "      <th>gpt-4o_time</th>\n",
       "      <th>finetuned_erd</th>\n",
       "      <th>finetuned_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬</td>\n",
       "      <td>None</td>\n",
       "      <td>0.022335</td>\n",
       "      <td>None</td>\n",
       "      <td>0.020827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ê¸°ì–µì˜ ë‹¤ë¦¬</td>\n",
       "      <td>None</td>\n",
       "      <td>0.020424</td>\n",
       "      <td>None</td>\n",
       "      <td>0.022652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±</td>\n",
       "      <td>None</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>None</td>\n",
       "      <td>0.026310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê°€ìƒ í”¼íŒ…ë£¸ ì„œë¹„ìŠ¤</td>\n",
       "      <td>None</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>None</td>\n",
       "      <td>0.020398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ìŠ¤ë§ˆíŠ¸ ê±´ê°• ê´€ë¦¬ ë¹„ì„œ</td>\n",
       "      <td>None</td>\n",
       "      <td>0.018303</td>\n",
       "      <td>None</td>\n",
       "      <td>0.019620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      project_title gpt-4o_erd  gpt-4o_time finetuned_erd  finetuned_time\n",
       "0   ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬       None     0.022335          None        0.020827\n",
       "1            ê¸°ì–µì˜ ë‹¤ë¦¬       None     0.020424          None        0.022652\n",
       "2  ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±       None     0.019332          None        0.026310\n",
       "3        ê°€ìƒ í”¼íŒ…ë£¸ ì„œë¹„ìŠ¤       None     0.015917          None        0.020398\n",
       "4      ìŠ¤ë§ˆíŠ¸ ê±´ê°• ê´€ë¦¬ ë¹„ì„œ       None     0.018303          None        0.019620"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for idx, row in df.iterrows():\n",
    "    user_input = parse_field(row['user_input'])\n",
    "    requirements = parse_field(row['total_requirements'])\n",
    "    project_info = parse_field(row['project_info'])\n",
    "\n",
    "    erd1, time1 = ERD_generate(user_input, requirements, project_info)\n",
    "    erd2, time2 = new_ERD_generate(user_input, requirements, project_info)\n",
    "\n",
    "    results.append({\n",
    "        \"project_title\": project_info['project_info']['title'],\n",
    "        \"gpt-4o_erd\": erd1,\n",
    "        \"gpt-4o_time\": time1,\n",
    "        \"finetuned_erd\": erd2,\n",
    "        \"finetuned_time\": time2\n",
    "    })\n",
    "    print(f\"[{idx+1}] {project_info['project_info']['title']} ì™„ë£Œ\")\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c98b6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¹„êµ ê²°ê³¼ê°€ erd_comparison_results.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "result_df.to_csv(\"erd_comparison_results.csv\", index=False)\n",
    "print(\"ë¹„êµ ê²°ê³¼ê°€ erd_comparison_results.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7b9f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4o ERD Table ìˆ˜: N/A\n",
      "Fine-tuned ERD Table ìˆ˜: N/A\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ì²« ë²ˆì§¸ í”„ë¡œì íŠ¸ ì˜ˆì‹œë¡œ êµ¬ì¡° ë¹„êµ\n",
    "print(\"GPT-4o ERD Table ìˆ˜:\", len(erd1['erd_tables']) if erd1 else \"N/A\")\n",
    "print(\"Fine-tuned ERD Table ìˆ˜:\", len(erd2['erd_tables']) if erd2 else \"N/A\")\n",
    "\n",
    "# (ë” ë³µì¡í•œ ë¹„êµ/ì‹œê°í™”ëŠ” ì´í›„ ì¶”ê°€ ê°€ëŠ¥)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8957739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_title</th>\n",
       "      <th>gpt-4o_erd</th>\n",
       "      <th>gpt-4o_time</th>\n",
       "      <th>finetuned_erd</th>\n",
       "      <th>finetuned_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ê¸°ì–µì˜ ë‹¤ë¦¬</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      project_title  gpt-4o_erd  gpt-4o_time  finetuned_erd  finetuned_time\n",
       "0   ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬         NaN     0.022335            NaN        0.020827\n",
       "1            ê¸°ì–µì˜ ë‹¤ë¦¬         NaN     0.020424            NaN        0.022652\n",
       "2  ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±         NaN     0.019332            NaN        0.026310"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_csv(\"erd_comparison_results.csv\")\n",
    "df.head(3)  # ì•ë¶€ë¶„ë§Œ ë¯¸ë¦¬ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de398f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "íŒŒì¸íŠœë‹ ëª¨ë¸ vs GPT-4o ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸\n",
    "í•œêµ­ì–´ ìš”êµ¬ì‚¬í•­ ë¶„ì„ íƒœìŠ¤í¬ í‰ê°€\n",
    "\n",
    "íŒŒì¼ëª…: benchmark_pja_vs_gpt4o.py\n",
    "ëª©ì : íŒŒì¸íŠœë‹ëœ ëª¨ë¸ê³¼ GPT-4oì˜ ì„±ëŠ¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµ ë¶„ì„\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "from sacrebleu import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "# ========================================================================================\n",
    "# ì „ì—­ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜\n",
    "# ========================================================================================\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ì •ì˜\n",
    "FINETUNED_MODEL = \"ft:gpt-4o-mini-2024-07-18:test:pja-erd-finetuning-model:BmOgyl6o\"  # íŒŒì¸íŠœë‹ëœ ëª¨ë¸\n",
    "BASELINE_MODEL = \"gpt-4o\"  # ë¹„êµ ëŒ€ìƒì¸ ê¸°ë³¸ GPT-4o ëª¨ë¸\n",
    "\n",
    "# API í˜¸ì¶œ ì„¤ì •\n",
    "TEMPERATURE = 0.2  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± ìˆëŠ” ì‘ë‹µ ìƒì„±\n",
    "CSV_FILE_PATH = \"hehe.csv\"  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” CSV íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "# í•œêµ­ì–´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì „ë¬¸ê°€ ì—­í•  ì •ì˜\n",
    "SYSTEM_PROMPT = \"\"\"ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. \n",
    "ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì´ê³  êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ ëª©ë¡ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­ê³¼ ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ì„ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ê³ , ê° ìš”êµ¬ì‚¬í•­ì€ ëª…í™•í•˜ê³  ì¸¡ì • ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "# ========================================================================================\n",
    "# í•µì‹¬ í•¨ìˆ˜ ì •ì˜\n",
    "# ========================================================================================\n",
    "\n",
    "def openai_chat_completion(model, user_input, project_info):\n",
    "    \"\"\"\n",
    "    OpenAI Chat Completion APIë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        model (str): ì‚¬ìš©í•  ëª¨ë¸ëª… (íŒŒì¸íŠœë‹ ëª¨ë¸ ë˜ëŠ” GPT-4o)\n",
    "        user_input (str): ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìš”êµ¬ì‚¬í•­ ì„¤ëª…\n",
    "        project_info (str): í”„ë¡œì íŠ¸ ì •ë³´ (JSON í˜•íƒœì˜ ë¬¸ìì—´)\n",
    "    \n",
    "    Returns:\n",
    "        str: ëª¨ë¸ì´ ìƒì„±í•œ ìš”êµ¬ì‚¬í•­ ëª©ë¡ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "í”„ë¡œì íŠ¸ ì •ë³´:\n",
    "{project_info}\n",
    "\n",
    "ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­:\n",
    "{user_input}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì¸ ìš”êµ¬ì‚¬í•­ ëª©ë¡ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. \n",
    "ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­ê³¼ ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ë¶ˆë¦¿ í¬ì¸íŠ¸ í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\"\"\"}\n",
    "        ]\n",
    "        \n",
    "        # OpenAI API í˜¸ì¶œ\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE,  # ì¼ê´€ì„± ìˆëŠ” ì‘ë‹µì„ ìœ„í•œ ë‚®ì€ ì˜¨ë„\n",
    "            max_tokens=2000  # ì¶©ë¶„í•œ ê¸¸ì´ì˜ ì‘ë‹µì„ ìœ„í•œ í† í° ì œí•œ\n",
    "        )\n",
    "        \n",
    "        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ê³µë°± ì œê±°\n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # API í˜¸ì¶œ ì‹¤íŒ¨ì‹œ ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥ ë° ë¹ˆ ë¬¸ìì—´ ë°˜í™˜\n",
    "        print(f\"API í˜¸ì¶œ ì˜¤ë¥˜ ({model}): {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def calculate_metrics(predictions, references):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        predictions (list): ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ ëª©ë¡\n",
    "        references (list): ì •ë‹µ(ground truth) í…ìŠ¤íŠ¸ ëª©ë¡\n",
    "    \n",
    "    Returns:\n",
    "        dict: ê³„ì‚°ëœ ì„±ëŠ¥ ë©”íŠ¸ë¦­ë“¤ (BLEU, ROUGE-L, ì •í™•ì¼ì¹˜ìœ¨)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. BLEU ì ìˆ˜ ê³„ì‚° - n-gram ê¸°ë°˜ ìœ ì‚¬ë„ ì¸¡ì •\n",
    "    # corpus_bleuëŠ” ì „ì²´ ì½”í¼ìŠ¤ì— ëŒ€í•œ BLEU ì ìˆ˜ë¥¼ ê³„ì‚°\n",
    "    bleu_score = corpus_bleu(predictions, [references]).score\n",
    "    \n",
    "    # 2. ROUGE-L ì ìˆ˜ ê³„ì‚° - ìµœì¥ ê³µí†µ ë¶€ë¶„ ìˆ˜ì—´ ê¸°ë°˜ ìœ ì‚¬ë„ ì¸¡ì •\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    rouge_scores = [scorer.score(ref, pred)['rougeL'].fmeasure \n",
    "                   for ref, pred in zip(references, predictions)]\n",
    "    rouge_l_score = np.mean(rouge_scores) * 100  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜\n",
    "    \n",
    "    # 3. ì •í™• ì¼ì¹˜ìœ¨ ê³„ì‚° - ì™„ì „íˆ ë™ì¼í•œ ì¶œë ¥ì˜ ë¹„ìœ¨\n",
    "    exact_matches = sum(1 for p, r in zip(predictions, references) \n",
    "                       if p.strip() == r.strip())\n",
    "    exact_match_rate = (exact_matches / len(references)) * 100\n",
    "    \n",
    "    # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜ (ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€)\n",
    "    return {\n",
    "        \"BLEU\": round(bleu_score, 2),\n",
    "        \"ROUGE-L\": round(rouge_l_score, 2),\n",
    "        \"ì •í™•ì¼ì¹˜ìœ¨(%)\": round(exact_match_rate, 2)\n",
    "    }\n",
    "\n",
    "def run_evaluation():\n",
    "    \"\"\"\n",
    "    ë©”ì¸ í‰ê°€ ì‹¤í–‰ í•¨ìˆ˜ - ì „ì²´ ì„±ëŠ¥ ë¹„êµ í”„ë¡œì„¸ìŠ¤ë¥¼ ê´€ë¦¬\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š íŒŒì¸íŠœë‹ ëª¨ë¸ vs GPT-4o ì„±ëŠ¥ ë¹„êµ ì‹œì‘\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 1. ë°ì´í„° ë¡œë“œ ë° ê²€ì¦\n",
    "    # ========================================================================================\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_FILE_PATH)\n",
    "        print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒ˜í”Œ\")\n",
    "        \n",
    "        # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "        required_columns = ['user_input', 'project_info', 'total_requirements']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 2. ëª¨ë¸ë³„ ì¶”ë¡  ì‹¤í–‰\n",
    "    # ========================================================================================\n",
    "    \n",
    "    # ê° ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "    results = {\n",
    "        FINETUNED_MODEL: [],  # íŒŒì¸íŠœë‹ ëª¨ë¸ ê²°ê³¼\n",
    "        BASELINE_MODEL: []    # GPT-4o ê²°ê³¼\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ”„ {len(df)}ê°œ ìƒ˜í”Œì— ëŒ€í•´ ëª¨ë¸ ì¶”ë¡  ì‹œì‘...\")\n",
    "    \n",
    "    # ê° ë°ì´í„° ìƒ˜í”Œì— ëŒ€í•´ ë‘ ëª¨ë¸ë¡œ ì¶”ë¡  ìˆ˜í–‰\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"ëª¨ë¸ ì¶”ë¡  ì§„í–‰\"):\n",
    "        user_input = row['user_input']        # ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ì„¤ëª…\n",
    "        project_info = row['project_info']    # í”„ë¡œì íŠ¸ ì •ë³´\n",
    "        \n",
    "        # íŒŒì¸íŠœë‹ ëª¨ë¸ë¡œ ì¶”ë¡ \n",
    "        print(f\"  ğŸ“ ìƒ˜í”Œ {idx+1}: íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡  ì¤‘...\")\n",
    "        ft_result = openai_chat_completion(FINETUNED_MODEL, user_input, project_info)\n",
    "        results[FINETUNED_MODEL].append(ft_result)\n",
    "        \n",
    "        # GPT-4o ëª¨ë¸ë¡œ ì¶”ë¡   \n",
    "        print(f\"  ğŸ“ ìƒ˜í”Œ {idx+1}: GPT-4o ì¶”ë¡  ì¤‘...\")\n",
    "        gpt4o_result = openai_chat_completion(BASELINE_MODEL, user_input, project_info)\n",
    "        results[BASELINE_MODEL].append(gpt4o_result)\n",
    "        \n",
    "        # API í˜¸ì¶œ ê°„ê²© ì¡°ì • (ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë°©ì§€)\n",
    "        # 0.5ì´ˆ ëŒ€ê¸°ë¡œ ì•ˆì •ì ì¸ API í˜¸ì¶œ ë³´ì¥\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # ì§„í–‰ ìƒí™© ì¶œë ¥ (10ê°œë§ˆë‹¤)\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"  âœ… {idx + 1}/{len(df)} ìƒ˜í”Œ ì™„ë£Œ\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚° ë° ê²°ê³¼ ì¶œë ¥\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ì •ë‹µ ë°ì´í„° (ground truth) ì¶”ì¶œ\n",
    "    references = df['ERD_data'].tolist()\n",
    "    \n",
    "    # ê° ëª¨ë¸ë³„ë¡œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    final_results = {}\n",
    "    for model_name, predictions in results.items():\n",
    "        # ëª¨ë¸ëª…ì„ í•œêµ­ì–´ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•œ ë³€í™˜\n",
    "        model_display_name = \"íŒŒì¸íŠœë‹ ëª¨ë¸\" if \"ft:\" in model_name else \"GPT-4o\"\n",
    "        \n",
    "        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "        metrics = calculate_metrics(predictions, references)\n",
    "        \n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"\\nğŸ¤– {model_display_name}\")\n",
    "        print(f\"   BLEU ì ìˆ˜: {metrics['BLEU']}\")\n",
    "        print(f\"   ROUGE-L ì ìˆ˜: {metrics['ROUGE-L']}\")\n",
    "        print(f\"   ì •í™• ì¼ì¹˜ìœ¨: {metrics['ì •í™•ì¼ì¹˜ìœ¨(%)']}%\")\n",
    "        \n",
    "        # ìµœì¢… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥\n",
    "        model_key = \"íŒŒì¸íŠœë‹_ëª¨ë¸\" if \"ft:\" in model_name else \"GPT-4o\"\n",
    "        final_results[model_key] = metrics\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 4. ê²°ê³¼ ì €ì¥\n",
    "    # ========================================================================================\n",
    "    \n",
    "    # JSON í˜•íƒœë¡œ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥\n",
    "    try:\n",
    "        with open(\"ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(final_results, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"\\nğŸ’¾ ê²°ê³¼ê°€ 'ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ìƒì„¸í•œ ì¶œë ¥ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥\n",
    "    try:\n",
    "        output_df = df.copy()\n",
    "        output_df['íŒŒì¸íŠœë‹_ëª¨ë¸_ì¶œë ¥'] = results[FINETUNED_MODEL]\n",
    "        output_df['GPT4o_ì¶œë ¥'] = results[BASELINE_MODEL]\n",
    "        output_df.to_csv(\"ëª¨ë¸_ì¶œë ¥_ë¹„êµ.csv\", index=False, encoding=\"utf-8\")\n",
    "        print(f\"ğŸ“„ ìƒì„¸ ì¶œë ¥ ê²°ê³¼ê°€ 'ëª¨ë¸_ì¶œë ¥_ë¹„êµ.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒì„¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 5. ì„±ëŠ¥ ì°¨ì´ ë¶„ì„\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì„±ëŠ¥ ì°¨ì´ ë¶„ì„\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if len(final_results) == 2:\n",
    "        ft_bleu = final_results['íŒŒì¸íŠœë‹_ëª¨ë¸']['BLEU']\n",
    "        gpt4o_bleu = final_results['GPT-4o']['BLEU']\n",
    "        bleu_diff = ft_bleu - gpt4o_bleu\n",
    "        \n",
    "        ft_rouge = final_results['íŒŒì¸íŠœë‹_ëª¨ë¸']['ROUGE-L']\n",
    "        gpt4o_rouge = final_results['GPT-4o']['ROUGE-L']\n",
    "        rouge_diff = ft_rouge - gpt4o_rouge\n",
    "        \n",
    "        print(f\"BLEU ì ìˆ˜ ì°¨ì´: {bleu_diff:+.2f} ({'í–¥ìƒ' if bleu_diff > 0 else 'ì €í•˜'})\")\n",
    "        print(f\"ROUGE-L ì ìˆ˜ ì°¨ì´: {rouge_diff:+.2f} ({'í–¥ìƒ' if rouge_diff > 0 else 'ì €í•˜'})\")\n",
    "        \n",
    "        # ì„±ëŠ¥ ê°œì„  ì—¬ë¶€ íŒë‹¨\n",
    "        if bleu_diff > 0 and rouge_diff > 0:\n",
    "            print(\"ğŸ‰ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ëª¨ë“  ì§€í‘œì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤!\")\n",
    "        elif bleu_diff < 0 and rouge_diff < 0:\n",
    "            print(\"âš ï¸  íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ê¸°ë³¸ ëª¨ë¸ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"ğŸ“ ì¼ë¶€ ì§€í‘œì—ì„œë§Œ ì„±ëŠ¥ í–¥ìƒì´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ========================================================================================\n",
    "# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„\n",
    "# ========================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # OpenAI API í‚¤ í™•ì¸\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
    "        print(\"   export OPENAI_API_KEY='your-api-key-here'\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"ğŸš€ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {CSV_FILE_PATH}\")\n",
    "    print(f\"ğŸ¤– íŒŒì¸íŠœë‹ ëª¨ë¸: {FINETUNED_MODEL}\")\n",
    "    print(f\"ğŸ¤– ê¸°ë³¸ ëª¨ë¸: {BASELINE_MODEL}\")\n",
    "    print(f\"ğŸŒ¡ï¸  ì˜¨ë„ ì„¤ì •: {TEMPERATURE}\")\n",
    "    \n",
    "    # ë©”ì¸ í‰ê°€ í•¨ìˆ˜ ì‹¤í–‰\n",
    "    run_evaluation()\n",
    "    \n",
    "    print(\"\\nâœ… ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9661fe58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m metrics\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2eae87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ê°œì„ ëœ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: hehe.csv\n",
      "ğŸ¤– íŒŒì¸íŠœë‹ ëª¨ë¸: ft:gpt-4o-mini-2024-07-18:test:pja-erd-finetuning-model:BmOgyrDW:ckpt-step-124\n",
      "ğŸ¤– ê¸°ë³¸ ëª¨ë¸: gpt-4o\n",
      "ğŸŒ¡ï¸ ì˜¨ë„ ì„¤ì •: 0.2\n",
      "ğŸ“Š íŒŒì¸íŠœë‹ ëª¨ë¸ vs GPT-4o ì„±ëŠ¥ ë¹„êµ ì‹œì‘ (ê°œì„  ë²„ì „)\n",
      "============================================================\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 138ê°œ ìƒ˜í”Œ\n",
      "ğŸ“‹ CSV ì»¬ëŸ¼: ['user_input', 'total_requirements', 'project_info', 'ERD_data']\n",
      "\n",
      "ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ“‹ ë°ì´í„° ìƒ˜í”Œ í™•ì¸:\n",
      "\n",
      "ìƒ˜í”Œ 1:\n",
      "  user_input: <class 'list'> - [{'projectName': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', 'projectTarget': 'í•™ìŠµì ë° êµìœ¡ì', 'mainFunction': ['ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ì‹œê°í™”', ...\n",
      "  total_requirements: <class 'list'> - [{'requirementType': 'FUNCTIONAL', 'content': 'ì‚¬ìš©ìëŠ” íšŒì›ê°€ì… ì‹œ ì´ë©”ì¼ ì¸ì¦ì„ í†µí•´ ê³„ì • ìƒì„±ì˜ ì•ˆì „ì„±ì„ ë†’ì¼ ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.'}, {'...\n",
      "  project_info: <class 'dict'> - {'project_info': {'title': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', 'category': 'ì›¹ì•±', 'target_users': ['í•™ìŠµì', 'êµìœ¡ì', 'ìŠ¤í„°ë”” ...\n",
      "  ERD_data: <class 'dict'> - {'erd_tables': [{'name': 'users', 'erd_columns': [{'name': 'user_id', 'data_type': 'SERIAL', 'is_pri...\n",
      "\n",
      "ìƒ˜í”Œ 2:\n",
      "  user_input: <class 'list'> - [{'projectName': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'projectTarget': 'ì¹˜ë§¤ í™˜ìì™€ ê·¸ ê°€ì¡±', 'mainFunction': ['ì¶”ì–µ ì‚¬ì§„ ê³µìœ  ë° ëŒ“ê¸€ ê¸°ëŠ¥', 'ê³¼ê±° ...\n",
      "  total_requirements: <class 'list'> - [{'requirementType': 'FUNCTIONAL', 'content': 'ì‚¬ìš©ìëŠ” ìµœëŒ€ 10ì¥ì˜ ì‚¬ì§„ì„ í•œ ë²ˆì— ì—…ë¡œë“œ í•  ìˆ˜ ìˆì–´ì•¼ í•˜ë©°, ê° ì‚¬ì§„ì— ëŒ€í•´ ì œëª©ê³¼ ì„¤ëª…...\n",
      "  project_info: <class 'dict'> - {'project_info': {'title': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'category': 'ì›¹ì•±', 'target_users': ['ì¹˜ë§¤ í™˜ì', 'ì¹˜ë§¤ í™˜ìì˜ ê°€ì¡±', 'ê°„ë³‘ì¸',...\n",
      "  ERD_data: <class 'dict'> - {'erd_tables': [{'name': 'Users', 'erd_columns': [{'name': 'user_id', 'data_type': 'ObjectId', 'is_p...\n",
      "\n",
      "ğŸ”„ 5ê°œ ìƒ˜í”Œì— ëŒ€í•´ ëª¨ë¸ ì¶”ë¡  ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 1 ì²˜ë¦¬ ì¤‘...\n",
      "   ì…ë ¥ íƒ€ì…: <class 'list'>\n",
      "   í”„ë¡œì íŠ¸ ì •ë³´ íƒ€ì…: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 2 ì²˜ë¦¬ ì¤‘...\n",
      "   ì…ë ¥ íƒ€ì…: <class 'list'>\n",
      "   í”„ë¡œì íŠ¸ ì •ë³´ íƒ€ì…: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:15<01:52, 37.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 3 ì²˜ë¦¬ ì¤‘...\n",
      "   ì…ë ¥ íƒ€ì…: <class 'list'>\n",
      "   í”„ë¡œì íŠ¸ ì •ë³´ íƒ€ì…: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:47<01:10, 35.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 4 ì²˜ë¦¬ ì¤‘...\n",
      "   ì…ë ¥ íƒ€ì…: <class 'list'>\n",
      "   í”„ë¡œì íŠ¸ ì •ë³´ íƒ€ì…: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:30<00:38, 38.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 5 ì²˜ë¦¬ ì¤‘...\n",
      "   ì…ë ¥ íƒ€ì…: <class 'list'>\n",
      "   í”„ë¡œì íŠ¸ ì •ë³´ íƒ€ì…: <class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:10<00:00, 38.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\n",
      "============================================================\n",
      "ğŸ“Š ì •ë‹µ ë°ì´í„° í˜•íƒœ í™•ì¸:\n",
      "  ì •ë‹µ 1: <class 'dict'> - {'erd_tables': [{'name': 'users', 'erd_columns': [{'name': 'user_id', 'data_type': 'SERIAL', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'email', 'data_type': 'VAR...\n",
      "  ì •ë‹µ 2: <class 'dict'> - {'erd_tables': [{'name': 'Users', 'erd_columns': [{'name': 'user_id', 'data_type': 'ObjectId', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'username', 'data_type':...\n",
      "\n",
      "ğŸ” íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶œë ¥ í™•ì¸:\n",
      "  ì¶œë ¥ 1: ì•„ë˜ëŠ” \"ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬\" í”„ë¡œì íŠ¸ì— ëŒ€í•œ ERD(Entity Relationship Diagram) ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ ì œê³µí•œ ê²ƒì…ë‹ˆë‹¤. ì´ ERDëŠ” ì‚¬ìš©ì, ìŠ¤í„°ë”” ê·¸ë£¹, í€´ì¦ˆ, ê³¼ì œ, ê³µì§€ì‚¬í•­ ë“±ê³¼ ê´€ë ¨ëœ í…Œì´ë¸” êµ¬ì¡°ì™€ ê´€ê³„ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"erd_tables\": [\n",
      "    {\n",
      "      \"name\": \"...\n",
      "  ì¶œë ¥ 2: ì•„ë˜ëŠ” \"ê¸°ì–µì˜ ë‹¤ë¦¬\" í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ERD(Entity Relationship Diagram) ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ERDëŠ” ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì„ ê¸°ë°˜ìœ¼ë¡œ í…Œì´ë¸” êµ¬ì¡°, ì»¬ëŸ¼ ì •ë³´, ê·¸ë¦¬ê³  ê´€ê³„ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"erd_tables\": [\n",
      "    {\n",
      "      \"name\": \"Users\",\n",
      "      \"columns\": [\n",
      "   ...\n",
      "\n",
      "ğŸ¤– íŒŒì¸íŠœë‹ ëª¨ë¸ ì„±ëŠ¥:\n",
      "   BLEU: 69.09\n",
      "   ROUGE-L: 81.11\n",
      "   ì •í™•ì¼ì¹˜ìœ¨(%): 0.0\n",
      "   ì˜ë¯¸ì _ìœ ì‚¬ë„(%): 64.95\n",
      "\n",
      "ğŸ” GPT-4o ì¶œë ¥ í™•ì¸:\n",
      "  ì¶œë ¥ 1: ì•„ë˜ëŠ” \"ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬\" í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ERD ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” í”„ë¡œì íŠ¸ ì„¤ëª…ê³¼ ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê° í…Œì´ë¸”ì€ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, í…Œì´ë¸” ê°„ì˜ ê´€ê³„ë„ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"name\": \"User\",\n",
      "      \"c...\n",
      "  ì¶œë ¥ 2: ```json\n",
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"name\": \"Users\",\n",
      "      \"columns\": [\n",
      "        {\n",
      "          \"name\": \"user_id\",\n",
      "          \"type\": \"ObjectId\",\n",
      "          \"primary_key\": true\n",
      "        },\n",
      "        {\n",
      "      ...\n",
      "\n",
      "ğŸ¤– GPT-4o ì„±ëŠ¥:\n",
      "   BLEU: 41.29\n",
      "   ROUGE-L: 36.56\n",
      "   ì •í™•ì¼ì¹˜ìœ¨(%): 0.0\n",
      "   ì˜ë¯¸ì _ìœ ì‚¬ë„(%): 71.65\n",
      "\n",
      "ğŸ’¾ ê²°ê³¼ê°€ 'ì„±ëŠ¥ë¹„êµ_ê²°ê³¼_ê°œì„ .json' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“„ ìƒì„¸ ì¶œë ¥ì´ 'ëª¨ë¸_ì¶œë ¥_ë¹„êµ_ê°œì„ .csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ì„±ëŠ¥ ì°¨ì´ ë¶„ì„\n",
      "============================================================\n",
      "BLEU ì°¨ì´: +27.80 (í–¥ìƒ)\n",
      "ROUGE-L ì°¨ì´: +44.55 (í–¥ìƒ)\n",
      "ì˜ë¯¸ì _ìœ ì‚¬ë„(%) ì°¨ì´: -6.70 (ì €í•˜)\n",
      "ğŸ‰ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤!\n",
      "\n",
      "âœ… ê°œì„ ëœ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "íŒŒì¸íŠœë‹ ëª¨ë¸ vs GPT-4o ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ (ê°œì„  ë²„ì „)\n",
    "í•œêµ­ì–´ ìš”êµ¬ì‚¬í•­ ë¶„ì„ íƒœìŠ¤í¬ í‰ê°€\n",
    "\n",
    "ì£¼ìš” ê°œì„ ì‚¬í•­:\n",
    "1. ì •ë‹µ ë°ì´í„° ì°¸ì¡° ì˜¤ë¥˜ ìˆ˜ì • (ERD_data -> total_requirements)\n",
    "2. JSON í˜•íƒœ ë°ì´í„° ì²˜ë¦¬ ë¡œì§ ì¶”ê°€\n",
    "3. ë” ì í•©í•œ í‰ê°€ ë©”íŠ¸ë¦­ ì¶”ê°€ (ì˜ë¯¸ì  ìœ ì‚¬ë„)\n",
    "4. ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "from sacrebleu import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "import ast\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ========================================================================================\n",
    "# ì „ì—­ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜\n",
    "# ========================================================================================\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ì •ì˜\n",
    "FINETUNED_MODEL = \"ft:gpt-4o-mini-2024-07-18:test:pja-erd-finetuning-model:BmOgyrDW:ckpt-step-124\"\n",
    "BASELINE_MODEL = \"gpt-4o\"\n",
    "\n",
    "# API í˜¸ì¶œ ì„¤ì •\n",
    "TEMPERATURE = 0.2\n",
    "CSV_FILE_PATH = \"hehe.csv\"\n",
    "\n",
    "# í•œêµ­ì–´ ERD ìƒì„± ì „ë¬¸ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (íŒŒì¸íŠœë‹ ëª©ì ì— ë§ê²Œ ìˆ˜ì •)\n",
    "SYSTEM_PROMPT = \"\"\"ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. \n",
    "ì‚¬ìš©ìì˜ í”„ë¡œì íŠ¸ ì„¤ëª…ê³¼ ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ERD(Entity Relationship Diagram) ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "ê° í…Œì´ë¸”ì˜ êµ¬ì¡°, ì»¬ëŸ¼ ì •ë³´, ê´€ê³„ë¥¼ ëª…í™•í•˜ê²Œ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "JSON í˜•íƒœë¡œ êµ¬ì¡°í™”ëœ ERD ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "# ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•œ ëª¨ë¸ (í•œêµ­ì–´ ì§€ì›)\n",
    "try:\n",
    "    semantic_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    SEMANTIC_SIMILARITY_AVAILABLE = True\n",
    "except:\n",
    "    print(\"âš ï¸ ì˜ë¯¸ì  ìœ ì‚¬ë„ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ë©”íŠ¸ë¦­ì€ ì œì™¸ë©ë‹ˆë‹¤.\")\n",
    "    SEMANTIC_SIMILARITY_AVAILABLE = False\n",
    "\n",
    "# ========================================================================================\n",
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "# ========================================================================================\n",
    "\n",
    "def safe_parse_json_string(json_str):\n",
    "    \"\"\"\n",
    "    JSON ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    if pd.isna(json_str) or json_str == '':\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # ë¬¸ìì—´ì´ ì´ë¯¸ ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°\n",
    "        if isinstance(json_str, (dict, list)):\n",
    "            return json_str\n",
    "        \n",
    "        # ë¬¸ìì—´ì„ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„\n",
    "        if isinstance(json_str, str):\n",
    "            # ast.literal_eval ë¨¼ì € ì‹œë„ (Python ë¦¬í„°ëŸ´)\n",
    "            try:\n",
    "                return ast.literal_eval(json_str)\n",
    "            except:\n",
    "                # json.loads ì‹œë„\n",
    "                return json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        print(f\"JSON íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "        return json_str  # ì›ë³¸ ë¬¸ìì—´ ë°˜í™˜\n",
    "\n",
    "def format_data_for_prompt(data):\n",
    "    \"\"\"\n",
    "    ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì í•©í•œ í˜•íƒœë¡œ í¬ë§·íŒ…\n",
    "    \"\"\"\n",
    "    if isinstance(data, str):\n",
    "        return data\n",
    "    elif isinstance(data, (dict, list)):\n",
    "        return json.dumps(data, ensure_ascii=False, indent=2)\n",
    "    else:\n",
    "        return str(data)\n",
    "\n",
    "def extract_text_content(data):\n",
    "    \"\"\"\n",
    "    JSON ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì—¬ ë¹„êµ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜\n",
    "    \"\"\"\n",
    "    if isinstance(data, str):\n",
    "        return data.strip()\n",
    "    elif isinstance(data, dict):\n",
    "        # ë”•ì…”ë„ˆë¦¬ì—ì„œ ì£¼ìš” í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ\n",
    "        text_parts = []\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, str):\n",
    "                text_parts.append(f\"{key}: {value}\")\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, str):\n",
    "                        text_parts.append(item)\n",
    "                    elif isinstance(item, dict):\n",
    "                        text_parts.append(json.dumps(item, ensure_ascii=False))\n",
    "        return \" \".join(text_parts)\n",
    "    elif isinstance(data, list):\n",
    "        # ë¦¬ìŠ¤íŠ¸ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ\n",
    "        text_parts = []\n",
    "        for item in data:\n",
    "            if isinstance(item, str):\n",
    "                text_parts.append(item)\n",
    "            elif isinstance(item, dict):\n",
    "                text_parts.append(json.dumps(item, ensure_ascii=False))\n",
    "        return \" \".join(text_parts)\n",
    "    else:\n",
    "        return str(data)\n",
    "\n",
    "# ========================================================================================\n",
    "# í•µì‹¬ í•¨ìˆ˜ ì •ì˜\n",
    "# ========================================================================================\n",
    "\n",
    "def openai_chat_completion(model, user_input, project_info):\n",
    "    \"\"\"\n",
    "    OpenAI Chat Completion APIë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ í˜•íƒœë¡œ í¬ë§·íŒ…\n",
    "        formatted_project_info = format_data_for_prompt(project_info)\n",
    "        formatted_user_input = format_data_for_prompt(user_input)\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "í”„ë¡œì íŠ¸ ì •ë³´:\n",
    "{formatted_project_info}\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "{formatted_user_input}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ERD ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "í…Œì´ë¸” êµ¬ì¡°, ì»¬ëŸ¼ ì •ë³´, ê´€ê³„ë¥¼ í¬í•¨í•œ JSON í˜•íƒœë¡œ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\"\"\"}\n",
    "        ]\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API í˜¸ì¶œ ì˜¤ë¥˜ ({model}): {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def calculate_semantic_similarity(predictions, references):\n",
    "    \"\"\"\n",
    "    ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    if not SEMANTIC_SIMILARITY_AVAILABLE:\n",
    "        return 0.0\n",
    "    \n",
    "    try:\n",
    "        # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ\n",
    "        pred_texts = [extract_text_content(pred) for pred in predictions]\n",
    "        ref_texts = [extract_text_content(ref) for ref in references]\n",
    "        \n",
    "        # ì„ë² ë”© ìƒì„±\n",
    "        pred_embeddings = semantic_model.encode(pred_texts)\n",
    "        ref_embeddings = semantic_model.encode(ref_texts)\n",
    "        \n",
    "        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "        similarities = []\n",
    "        for pred_emb, ref_emb in zip(pred_embeddings, ref_embeddings):\n",
    "            similarity = cosine_similarity([pred_emb], [ref_emb])[0][0]\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        return np.mean(similarities) * 100\n",
    "    except Exception as e:\n",
    "        print(f\"ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def calculate_metrics(predictions, references):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ\n",
    "    pred_texts = [extract_text_content(pred) for pred in predictions]\n",
    "    ref_texts = [extract_text_content(ref) for ref in references]\n",
    "    \n",
    "    # ë¹ˆ í…ìŠ¤íŠ¸ í•„í„°ë§\n",
    "    valid_pairs = [(p, r) for p, r in zip(pred_texts, ref_texts) if p.strip() and r.strip()]\n",
    "    \n",
    "    if not valid_pairs:\n",
    "        return {\n",
    "            \"BLEU\": 0.0,\n",
    "            \"ROUGE-L\": 0.0,\n",
    "            \"ì •í™•ì¼ì¹˜ìœ¨(%)\": 0.0,\n",
    "            \"ì˜ë¯¸ì _ìœ ì‚¬ë„(%)\": 0.0\n",
    "        }\n",
    "    \n",
    "    valid_preds, valid_refs = zip(*valid_pairs)\n",
    "    \n",
    "    # 1. BLEU ì ìˆ˜ ê³„ì‚°\n",
    "    try:\n",
    "        bleu_score = corpus_bleu(list(valid_preds), [list(valid_refs)]).score\n",
    "    except:\n",
    "        bleu_score = 0.0\n",
    "    \n",
    "    # 2. ROUGE-L ì ìˆ˜ ê³„ì‚°\n",
    "    try:\n",
    "        scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "        rouge_scores = [scorer.score(ref, pred)['rougeL'].fmeasure \n",
    "                       for ref, pred in zip(valid_refs, valid_preds)]\n",
    "        rouge_l_score = np.mean(rouge_scores) * 100\n",
    "    except:\n",
    "        rouge_l_score = 0.0\n",
    "    \n",
    "    # 3. ì •í™• ì¼ì¹˜ìœ¨ ê³„ì‚°\n",
    "    exact_matches = sum(1 for p, r in zip(valid_preds, valid_refs) \n",
    "                       if p.strip() == r.strip())\n",
    "    exact_match_rate = (exact_matches / len(valid_pairs)) * 100\n",
    "    \n",
    "    # 4. ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    semantic_similarity = calculate_semantic_similarity(predictions, references)\n",
    "    \n",
    "    return {\n",
    "        \"BLEU\": round(bleu_score, 2),\n",
    "        \"ROUGE-L\": round(rouge_l_score, 2),\n",
    "        \"ì •í™•ì¼ì¹˜ìœ¨(%)\": round(exact_match_rate, 2),\n",
    "        \"ì˜ë¯¸ì _ìœ ì‚¬ë„(%)\": round(semantic_similarity, 2)\n",
    "    }\n",
    "\n",
    "def run_evaluation():\n",
    "    \"\"\"\n",
    "    ë©”ì¸ í‰ê°€ ì‹¤í–‰ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š íŒŒì¸íŠœë‹ ëª¨ë¸ vs GPT-4o ì„±ëŠ¥ ë¹„êµ ì‹œì‘ (ê°œì„  ë²„ì „)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 1. ë°ì´í„° ë¡œë“œ ë° ê²€ì¦\n",
    "    # ========================================================================================\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_FILE_PATH)\n",
    "        print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒ˜í”Œ\")\n",
    "        \n",
    "        # ì»¬ëŸ¼ ì •ë³´ ì¶œë ¥\n",
    "        print(f\"ğŸ“‹ CSV ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "        \n",
    "        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ (ìˆ˜ì •ëœ ë²„ì „)\n",
    "        required_columns = ['user_input', 'project_info', 'total_requirements', 'ERD_data']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            print(f\"âš ï¸ ì¼ë¶€ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}\")\n",
    "            print(\"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    print(\"\\nğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "    \n",
    "    # JSON ë¬¸ìì—´ì„ íŒŒì‹±\n",
    "    for col in ['user_input', 'project_info', 'total_requirements', 'ERD_data']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(safe_parse_json_string)\n",
    "    \n",
    "    # ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œì˜ ë°ì´í„° í˜•íƒœ í™•ì¸\n",
    "    print(\"\\nğŸ“‹ ë°ì´í„° ìƒ˜í”Œ í™•ì¸:\")\n",
    "    for i, row in df.head(2).iterrows():\n",
    "        print(f\"\\nìƒ˜í”Œ {i+1}:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"  {col}: {type(row[col])} - {str(row[col])[:100]}...\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 2. ëª¨ë¸ë³„ ì¶”ë¡  ì‹¤í–‰ (ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸)\n",
    "    # ========================================================================================\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜ ì œí•œ (ë¹„ìš© ì ˆì•½)\n",
    "    test_samples = min(5, len(df))  # ìµœëŒ€ 5ê°œ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸\n",
    "    test_df = df.head(test_samples).copy()\n",
    "    \n",
    "    print(f\"\\nğŸ”„ {test_samples}ê°œ ìƒ˜í”Œì— ëŒ€í•´ ëª¨ë¸ ì¶”ë¡  ì‹œì‘...\")\n",
    "    \n",
    "    results = {\n",
    "        FINETUNED_MODEL: [],\n",
    "        BASELINE_MODEL: []\n",
    "    }\n",
    "    \n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"ëª¨ë¸ ì¶”ë¡  ì§„í–‰\"):\n",
    "        user_input = row['user_input']\n",
    "        project_info = row['project_info']\n",
    "        \n",
    "        print(f\"\\nğŸ“ ìƒ˜í”Œ {idx+1} ì²˜ë¦¬ ì¤‘...\")\n",
    "        print(f\"   ì…ë ¥ íƒ€ì…: {type(user_input)}\")\n",
    "        print(f\"   í”„ë¡œì íŠ¸ ì •ë³´ íƒ€ì…: {type(project_info)}\")\n",
    "        \n",
    "        # íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡ \n",
    "        ft_result = openai_chat_completion(FINETUNED_MODEL, user_input, project_info)\n",
    "        results[FINETUNED_MODEL].append(ft_result)\n",
    "        \n",
    "        # GPT-4o ì¶”ë¡ \n",
    "        gpt4o_result = openai_chat_completion(BASELINE_MODEL, user_input, project_info)\n",
    "        results[BASELINE_MODEL].append(gpt4o_result)\n",
    "        \n",
    "        time.sleep(1.0)  # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë°©ì§€\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ì •ë‹µ ë°ì´í„° - ERD_dataë¥¼ ì •ë‹µìœ¼ë¡œ ì‚¬ìš© (íŒŒì¸íŠœë‹ ëª©ì ì— ë§ê²Œ)\n",
    "    references = test_df['ERD_data'].tolist()\n",
    "    \n",
    "    print(f\"ğŸ“Š ì •ë‹µ ë°ì´í„° í˜•íƒœ í™•ì¸:\")\n",
    "    for i, ref in enumerate(references[:2]):\n",
    "        print(f\"  ì •ë‹µ {i+1}: {type(ref)} - {str(ref)[:200]}...\")\n",
    "    \n",
    "    final_results = {}\n",
    "    for model_name, predictions in results.items():\n",
    "        model_display_name = \"íŒŒì¸íŠœë‹ ëª¨ë¸\" if \"ft:\" in model_name else \"GPT-4o\"\n",
    "        \n",
    "        print(f\"\\nğŸ” {model_display_name} ì¶œë ¥ í™•ì¸:\")\n",
    "        for i, pred in enumerate(predictions[:2]):\n",
    "            print(f\"  ì¶œë ¥ {i+1}: {str(pred)[:200]}...\")\n",
    "        \n",
    "        metrics = calculate_metrics(predictions, references)\n",
    "        \n",
    "        print(f\"\\nğŸ¤– {model_display_name} ì„±ëŠ¥:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"   {metric_name}: {value}\")\n",
    "        \n",
    "        model_key = \"íŒŒì¸íŠœë‹_ëª¨ë¸\" if \"ft:\" in model_name else \"GPT-4o\"\n",
    "        final_results[model_key] = metrics\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 4. ê²°ê³¼ ì €ì¥ ë° ë¶„ì„\n",
    "    # ========================================================================================\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    try:\n",
    "        with open(\"ì„±ëŠ¥ë¹„êµ_ê²°ê³¼_ê°œì„ .json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(final_results, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"\\nğŸ’¾ ê²°ê³¼ê°€ 'ì„±ëŠ¥ë¹„êµ_ê²°ê³¼_ê°œì„ .json' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ìƒì„¸ ê²°ê³¼ ì €ì¥\n",
    "    try:\n",
    "        output_df = test_df.copy()\n",
    "        output_df['íŒŒì¸íŠœë‹_ëª¨ë¸_ì¶œë ¥'] = results[FINETUNED_MODEL]\n",
    "        output_df['GPT4o_ì¶œë ¥'] = results[BASELINE_MODEL]\n",
    "        output_df.to_csv(\"ëª¨ë¸_ì¶œë ¥_ë¹„êµ_ê°œì„ .csv\", index=False, encoding=\"utf-8\")\n",
    "        print(f\"ğŸ“„ ìƒì„¸ ì¶œë ¥ì´ 'ëª¨ë¸_ì¶œë ¥_ë¹„êµ_ê°œì„ .csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒì„¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ì„±ëŠ¥ ì°¨ì´ ë¶„ì„\n",
    "    if len(final_results) == 2:\n",
    "        print(f\"\\nğŸ“Š ì„±ëŠ¥ ì°¨ì´ ë¶„ì„\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        ft_metrics = final_results['íŒŒì¸íŠœë‹_ëª¨ë¸']\n",
    "        gpt4o_metrics = final_results['GPT-4o']\n",
    "        \n",
    "        for metric in ['BLEU', 'ROUGE-L', 'ì˜ë¯¸ì _ìœ ì‚¬ë„(%)']:\n",
    "            if metric in ft_metrics and metric in gpt4o_metrics:\n",
    "                diff = ft_metrics[metric] - gpt4o_metrics[metric]\n",
    "                print(f\"{metric} ì°¨ì´: {diff:+.2f} ({'í–¥ìƒ' if diff > 0 else 'ì €í•˜'})\")\n",
    "        \n",
    "        # ì¢…í•© í‰ê°€\n",
    "        improvements = sum(1 for metric in ['BLEU', 'ROUGE-L', 'ì˜ë¯¸ì _ìœ ì‚¬ë„(%)'] \n",
    "                          if ft_metrics.get(metric, 0) > gpt4o_metrics.get(metric, 0))\n",
    "        \n",
    "        if improvements >= 2:\n",
    "            print(\"ğŸ‰ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤!\")\n",
    "        elif improvements == 1:\n",
    "            print(\"ğŸ“ ì¼ë¶€ ì§€í‘œì—ì„œ ì„±ëŠ¥ í–¥ìƒì´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"âš ï¸ íŒŒì¸íŠœë‹ íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤. ë°ì´í„°ë‚˜ ë°©ë²•ë¡  ì¬ê²€í† ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ========================================================================================\n",
    "# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„\n",
    "# ========================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
    "        print(\"   export OPENAI_API_KEY='your-api-key-here'\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"ğŸš€ ê°œì„ ëœ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {CSV_FILE_PATH}\")\n",
    "    print(f\"ğŸ¤– íŒŒì¸íŠœë‹ ëª¨ë¸: {FINETUNED_MODEL}\")\n",
    "    print(f\"ğŸ¤– ê¸°ë³¸ ëª¨ë¸: {BASELINE_MODEL}\")\n",
    "    print(f\"ğŸŒ¡ï¸ ì˜¨ë„ ì„¤ì •: {TEMPERATURE}\")\n",
    "    \n",
    "    run_evaluation()\n",
    "    \n",
    "    print(\"\\nâœ… ê°œì„ ëœ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0829e836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 16:55:04.859000 24772 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "c:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: hehe.csv\n",
      "ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸: ft:gpt-4o-mini-2024-07-18:test:pja-erd-finetuning-model:BmOgyrDW:ckpt-step-124\n",
      "ğŸ¤– GPT-4o-mini: gpt-4o-mini\n",
      "ğŸ”¥ GPT-4o: gpt-4o\n",
      "ğŸŒ¡ï¸ ì˜¨ë„ ì„¤ì •: 0.2\n",
      "ğŸ“Š 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: íŒŒì¸íŠœë‹ vs GPT-4o-mini vs GPT-4o\n",
      "================================================================================\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 138ê°œ ìƒ˜í”Œ\n",
      "ğŸ“‹ CSV ì»¬ëŸ¼: ['user_input', 'total_requirements', 'project_info', 'ERD_data']\n",
      "\n",
      "ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ”„ 5ê°œ ìƒ˜í”Œì— ëŒ€í•´ 3ê°œ ëª¨ë¸ ì¶”ë¡  ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 1 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  20%|â–ˆâ–ˆ        | 1/5 [01:02<04:09, 62.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 2 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [02:03<03:04, 61.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 3 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [02:52<01:52, 56.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 4 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [03:42<00:53, 53.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 5 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [04:33<00:00, 54.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ 3ê°œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ğŸ” íŒŒì¸íŠœë‹_ëª¨ë¸ ì¶œë ¥ í™•ì¸:\n",
      "  ì¶œë ¥ 1: {\n",
      "  \"erd_tables\": [\n",
      "    {\n",
      "      \"name\": \"ì‚¬ìš©ì\",\n",
      "      \"erd_columns\": [\n",
      "        {\n",
      "          \"name\": \"ì‚¬ìš©ìID\",\n",
      "          \"data_type\": \"INTEGER\",\n",
      "         ...\n",
      "  ì¶œë ¥ 2: {\n",
      "  \"erd_tables\": [\n",
      "    {\n",
      "      \"name\": \"ì‚¬ìš©ì\",\n",
      "      \"erd_columns\": [\n",
      "        {\n",
      "          \"name\": \"ì‚¬ìš©ìID\",\n",
      "          \"data_type\": \"ObjectId\",\n",
      "        ...\n",
      "\n",
      "ğŸ¤– íŒŒì¸íŠœë‹_ëª¨ë¸ ì„±ëŠ¥:\n",
      "   BLEU: 75.17\n",
      "   ROUGE-L: 79.73\n",
      "   ì •í™•ì¼ì¹˜ìœ¨(%): 0.0\n",
      "   ì˜ë¯¸ì _ìœ ì‚¬ë„(%): 94.29\n",
      "\n",
      "ğŸ” GPT-4o-mini ì¶œë ¥ í™•ì¸:\n",
      "  ì¶œë ¥ 1: {\n",
      "  \"erd_tables\": [\n",
      "    {\n",
      "      \"name\": \"users\",\n",
      "      \"erd_columns\": [\n",
      "        {\n",
      "          \"name\": \"user_id\",\n",
      "          \"data_type\": \"SERIAL\",\n",
      "      ...\n",
      "  ì¶œë ¥ 2: {\n",
      "  \"erd_tables\": [\n",
      "    {\n",
      "      \"name\": \"Users\",\n",
      "      \"erd_columns\": [\n",
      "        {\n",
      "          \"name\": \"user_id\",\n",
      "          \"data_type\": \"ObjectId\",\n",
      "    ...\n",
      "\n",
      "ğŸ¤– GPT-4o-mini ì„±ëŠ¥:\n",
      "   BLEU: 84.07\n",
      "   ROUGE-L: 84.61\n",
      "   ì •í™•ì¼ì¹˜ìœ¨(%): 0.0\n",
      "   ì˜ë¯¸ì _ìœ ì‚¬ë„(%): 95.98\n",
      "\n",
      "ğŸ” GPT-4o ì¶œë ¥ í™•ì¸:\n",
      "  ì¶œë ¥ 1: {\n",
      "  \"erd_tables\": [\n",
      "    {\n",
      "      \"name\": \"users\",\n",
      "      \"erd_columns\": [\n",
      "        {\n",
      "          \"name\": \"user_id\",\n",
      "          \"data_type\": \"serial\",\n",
      "      ...\n",
      "  ì¶œë ¥ 2: {\n",
      "  \"erd_tables\": [\n",
      "    {\n",
      "      \"name\": \"Users\",\n",
      "      \"erd_columns\": [\n",
      "        {\n",
      "          \"name\": \"user_id\",\n",
      "          \"data_type\": \"ObjectId\",\n",
      "    ...\n",
      "\n",
      "ğŸ¤– GPT-4o ì„±ëŠ¥:\n",
      "   BLEU: 78.05\n",
      "   ROUGE-L: 81.41\n",
      "   ì •í™•ì¼ì¹˜ìœ¨(%): 0.0\n",
      "   ì˜ë¯¸ì _ìœ ì‚¬ë„(%): 95.59\n",
      "\n",
      "ğŸ“Š ì¢…í•© ì„±ëŠ¥ ë¹„êµ ë¶„ì„\n",
      "================================================================================\n",
      "ë©”íŠ¸ë¦­             íŒŒì¸íŠœë‹         4o-mini      GPT-4o       vs mini      vs 4o       \n",
      "--------------------------------------------------------------------------------\n",
      "BLEU            75.17        84.07        78.05        -8.90        -2.88       \n",
      "ROUGE-L         79.73        84.61        81.41        -4.88        -1.68       \n",
      "ì˜ë¯¸ì _ìœ ì‚¬ë„(%)      94.29        95.98        95.59        -1.69        -1.30       \n",
      "\n",
      "ğŸ¯ íŒŒì¸íŠœë‹ íš¨ê³¼ ë¶„ì„\n",
      "================================================================================\n",
      "ğŸ“ˆ ë² ì´ìŠ¤ ëª¨ë¸(GPT-4o-mini) ëŒ€ë¹„ íŒŒì¸íŠœë‹ ê°œì„ ë„:\n",
      "  BLEU: -8.90 (-10.6%)\n",
      "  ROUGE-L: -4.88 (-5.8%)\n",
      "  ì˜ë¯¸ì _ìœ ì‚¬ë„(%): -1.69 (-1.8%)\n",
      "\n",
      "ğŸ”¥ í”Œë˜ê·¸ì‹­ ëª¨ë¸(GPT-4o) ëŒ€ë¹„ íŒŒì¸íŠœë‹ ì„±ëŠ¥:\n",
      "  BLEU: -2.88 (ì—´ì„¸)\n",
      "  ROUGE-L: -1.68 (ì—´ì„¸)\n",
      "  ì˜ë¯¸ì _ìœ ì‚¬ë„(%): -1.30 (ì—´ì„¸)\n",
      "\n",
      "ğŸ† ìµœì¢… ê²°ë¡ \n",
      "================================================================================\n",
      "âš ï¸ íŒŒì¸íŠœë‹ íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤.\n",
      "ğŸ“ í”Œë˜ê·¸ì‹­ ëª¨ë¸ ëŒ€ë¹„ë¡œëŠ” ì•„ì§ ê°œì„  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ’° ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„:\n",
      "  íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„ìš©: GPT-4oì˜ ~10% (í›¨ì”¬ ì €ë ´)\n",
      "  ì¶”ë¡  ì†ë„: GPT-4oë³´ë‹¤ ë¹ ë¦„\n",
      "\n",
      "ğŸ’¾ ê²°ê³¼ê°€ '3ëª¨ë¸_ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "âœ… 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3ê°œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: íŒŒì¸íŠœë‹ vs GPT-4o-mini vs GPT-4o\n",
    "íŒŒì¸íŠœë‹ íš¨ê³¼ë¥¼ ëª…í™•í•˜ê²Œ ì¸¡ì •í•˜ê¸° ìœ„í•œ ì™„ì „í•œ ë¹„êµ\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "from sacrebleu import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "import ast\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ========================================================================================\n",
    "# ì „ì—­ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜\n",
    "# ========================================================================================\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  3ê°œ ëª¨ë¸ ì •ì˜\n",
    "FINETUNED_MODEL = \"ft:gpt-4o-mini-2024-07-18:test:pja-erd-finetuning-model:BmOgyrDW:ckpt-step-124\"\n",
    "BASELINE_MINI_MODEL = \"gpt-4o-mini\"  # íŒŒì¸íŠœë‹ ë² ì´ìŠ¤ ëª¨ë¸\n",
    "BASELINE_4O_MODEL = \"gpt-4o\"         # í”Œë˜ê·¸ì‹­ ëª¨ë¸\n",
    "\n",
    "# API í˜¸ì¶œ ì„¤ì •\n",
    "TEMPERATURE = 0.2\n",
    "CSV_FILE_PATH = \"hehe.csv\"\n",
    "\n",
    "# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "ë‹¹ì‹ ì€ ERD ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ì™„ì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "**í•µì‹¬ ì›ì¹™:**\n",
    "- ë°±ìŠ¬ë˜ì‹œ(\\\\) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€\n",
    "- erd_relationshipsì˜ ëª¨ë“  í…Œì´ë¸”ê³¼ ì™¸ë˜í‚¤ëŠ” ë°˜ë“œì‹œ erd_tablesì— ì¡´ì¬í•´ì•¼ í•¨\n",
    "- ì™¸ë˜í‚¤ ì»¬ëŸ¼ì€ is_foreign_key: true ì„¤ì • í•„ìˆ˜\n",
    "- ìˆœìˆ˜ JSONë§Œ ì‘ë‹µ (ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ê¸ˆì§€)\n",
    "**ì„¤ê³„ ìˆœì„œ:**\n",
    "1. ì—”í‹°í‹° ì‹ë³„ â†’ 2. ì†ì„±/ê¸°ë³¸í‚¤ ì •ì˜ â†’ 3. ê´€ê³„ ë¶„ì„/ì™¸ë˜í‚¤ ì¶”ê°€ â†’ 4. ê´€ê³„ ì •ë³´ ì‘ì„±\n",
    "**ì¤‘ìš”: ëª¨ë“  ê´€ê³„ì˜ í…Œì´ë¸”ëª…ê³¼ ì™¸ë˜í‚¤ê°€ í…Œì´ë¸” ì •ì˜ì™€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.**\n",
    "\"\"\"\n",
    "\n",
    "# ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•œ ëª¨ë¸\n",
    "try:\n",
    "    semantic_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    SEMANTIC_SIMILARITY_AVAILABLE = True\n",
    "except:\n",
    "    print(\"âš ï¸ ì˜ë¯¸ì  ìœ ì‚¬ë„ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ë©”íŠ¸ë¦­ì€ ì œì™¸ë©ë‹ˆë‹¤.\")\n",
    "    SEMANTIC_SIMILARITY_AVAILABLE = False\n",
    "\n",
    "# ========================================================================================\n",
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "# ========================================================================================\n",
    "\n",
    "def safe_parse_json_string(json_str):\n",
    "    \"\"\"JSON ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if pd.isna(json_str) or json_str == '':\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if isinstance(json_str, (dict, list)):\n",
    "            return json_str\n",
    "        \n",
    "        if isinstance(json_str, str):\n",
    "            try:\n",
    "                return ast.literal_eval(json_str)\n",
    "            except:\n",
    "                return json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        print(f\"JSON íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "        return json_str\n",
    "\n",
    "def format_data_for_prompt(data):\n",
    "    \"\"\"ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì í•©í•œ í˜•íƒœë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    if isinstance(data, str):\n",
    "        return data\n",
    "    elif isinstance(data, (dict, list)):\n",
    "        return json.dumps(data, ensure_ascii=False, indent=2)\n",
    "    else:\n",
    "        return str(data)\n",
    "\n",
    "def extract_text_content(data):\n",
    "    \"\"\"JSON ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì—¬ ë¹„êµ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜\"\"\"\n",
    "    if isinstance(data, str):\n",
    "        return data.strip()\n",
    "    elif isinstance(data, dict):\n",
    "        text_parts = []\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, str):\n",
    "                text_parts.append(f\"{key}: {value}\")\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, str):\n",
    "                        text_parts.append(item)\n",
    "                    elif isinstance(item, dict):\n",
    "                        text_parts.append(json.dumps(item, ensure_ascii=False))\n",
    "        return \" \".join(text_parts)\n",
    "    elif isinstance(data, list):\n",
    "        text_parts = []\n",
    "        for item in data:\n",
    "            if isinstance(item, str):\n",
    "                text_parts.append(item)\n",
    "            elif isinstance(item, dict):\n",
    "                text_parts.append(json.dumps(item, ensure_ascii=False))\n",
    "        return \" \".join(text_parts)\n",
    "    else:\n",
    "        return str(data)\n",
    "\n",
    "# ========================================================================================\n",
    "# í•µì‹¬ í•¨ìˆ˜ ì •ì˜\n",
    "# ========================================================================================\n",
    "\n",
    "def openai_chat_completion(model, user_input, project_info):\n",
    "    \"\"\"OpenAI Chat Completion APIë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        formatted_project_info = format_data_for_prompt(project_info)\n",
    "        formatted_user_input = format_data_for_prompt(user_input)\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "í”„ë¡œì íŠ¸ ì •ë³´:\n",
    "{formatted_project_info}\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "{formatted_user_input}\n",
    "\n",
    "  **í•„ìˆ˜ JSON í˜•ì‹:**\n",
    "  {{\n",
    "    \"erd_tables\": [{{\n",
    "      \"name\": \"í…Œì´ë¸”ëª…\",\n",
    "      \"erd_columns\": [{{\n",
    "        \"name\": \"ì»¬ëŸ¼ëª…\",\n",
    "        \"data_type\": \"íƒ€ì…\",\n",
    "        \"is_primary_key\": true/false,\n",
    "        \"is_foreign_key\": true/false,\n",
    "        \"is_nullable\": true/false\n",
    "      }}]\n",
    "    }}],\n",
    "    \"erd_relationships\": [{{\n",
    "      \"from_table\": \"ì‹œì‘í…Œì´ë¸”\",\n",
    "      \"to_table\": \"ëí…Œì´ë¸”\",\n",
    "      \"relationship_type\": \"one-to-many\",\n",
    "      \"foreign_key\": \"ì™¸ë˜í‚¤ëª…\",\n",
    "      \"constraint_name\": \"ì œì•½ì¡°ê±´ëª…\"\n",
    "    }}]\n",
    "  }}\n",
    "  **í•µì‹¬ ê·œì¹™:**\n",
    "  1. ê´€ê³„ì˜ ëª¨ë“  í…Œì´ë¸”ëª…ì´ erd_tablesì— ì¡´ì¬í•´ì•¼ í•¨\n",
    "  2. ê´€ê³„ì˜ ëª¨ë“  foreign_keyê°€ í•´ë‹¹ í…Œì´ë¸” ì»¬ëŸ¼ì— ì¡´ì¬í•´ì•¼ í•¨\n",
    "  3. ì™¸ë˜í‚¤ëŠ” is_foreign_key: true ì„¤ì •\n",
    "  4. ìµœì†Œ 5ê°œ í…Œì´ë¸”, ë°±ìŠ¬ë˜ì‹œ ê¸ˆì§€, ìˆœìˆ˜ JSONë§Œ\n",
    "  ìœ„ ê·œì¹™ì„ ì§€ì¼œ ì™„ì „í•œ ERDë¥¼ ìƒì„±í•˜ì„¸ìš”!\n",
    "\n",
    "\"\"\"}\n",
    "        ]\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API í˜¸ì¶œ ì˜¤ë¥˜ ({model}): {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def calculate_semantic_similarity(predictions, references):\n",
    "    \"\"\"ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if not SEMANTIC_SIMILARITY_AVAILABLE:\n",
    "        return 0.0\n",
    "    \n",
    "    try:\n",
    "        pred_texts = [extract_text_content(pred) for pred in predictions]\n",
    "        ref_texts = [extract_text_content(ref) for ref in references]\n",
    "        \n",
    "        pred_embeddings = semantic_model.encode(pred_texts)\n",
    "        ref_embeddings = semantic_model.encode(ref_texts)\n",
    "        \n",
    "        similarities = []\n",
    "        for pred_emb, ref_emb in zip(pred_embeddings, ref_embeddings):\n",
    "            similarity = cosine_similarity([pred_emb], [ref_emb])[0][0]\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        return np.mean(similarities) * 100\n",
    "    except Exception as e:\n",
    "        print(f\"ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def calculate_metrics(predictions, references):\n",
    "    \"\"\"ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    pred_texts = [extract_text_content(pred) for pred in predictions]\n",
    "    ref_texts = [extract_text_content(ref) for ref in references]\n",
    "    \n",
    "    valid_pairs = [(p, r) for p, r in zip(pred_texts, ref_texts) if p.strip() and r.strip()]\n",
    "    \n",
    "    if not valid_pairs:\n",
    "        return {\n",
    "            \"BLEU\": 0.0,\n",
    "            \"ROUGE-L\": 0.0,\n",
    "            \"ì •í™•ì¼ì¹˜ìœ¨(%)\": 0.0,\n",
    "            \"ì˜ë¯¸ì _ìœ ì‚¬ë„(%)\": 0.0\n",
    "        }\n",
    "    \n",
    "    valid_preds, valid_refs = zip(*valid_pairs)\n",
    "    \n",
    "    # BLEU ì ìˆ˜ ê³„ì‚°\n",
    "    try:\n",
    "        bleu_score = corpus_bleu(list(valid_preds), [list(valid_refs)]).score\n",
    "    except:\n",
    "        bleu_score = 0.0\n",
    "    \n",
    "    # ROUGE-L ì ìˆ˜ ê³„ì‚°\n",
    "    try:\n",
    "        scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "        rouge_scores = [scorer.score(ref, pred)['rougeL'].fmeasure \n",
    "                       for ref, pred in zip(valid_refs, valid_preds)]\n",
    "        rouge_l_score = np.mean(rouge_scores) * 100\n",
    "    except:\n",
    "        rouge_l_score = 0.0\n",
    "    \n",
    "    # ì •í™• ì¼ì¹˜ìœ¨ ê³„ì‚°\n",
    "    exact_matches = sum(1 for p, r in zip(valid_preds, valid_refs) \n",
    "                       if p.strip() == r.strip())\n",
    "    exact_match_rate = (exact_matches / len(valid_pairs)) * 100\n",
    "    \n",
    "    # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    semantic_similarity = calculate_semantic_similarity(predictions, references)\n",
    "    \n",
    "    return {\n",
    "        \"BLEU\": round(bleu_score, 2),\n",
    "        \"ROUGE-L\": round(rouge_l_score, 2),\n",
    "        \"ì •í™•ì¼ì¹˜ìœ¨(%)\": round(exact_match_rate, 2),\n",
    "        \"ì˜ë¯¸ì _ìœ ì‚¬ë„(%)\": round(semantic_similarity, 2)\n",
    "    }\n",
    "\n",
    "def run_three_model_evaluation():\n",
    "    \"\"\"3ê°œ ëª¨ë¸ ë¹„êµ í‰ê°€ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    print(\"ğŸ“Š 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: íŒŒì¸íŠœë‹ vs GPT-4o-mini vs GPT-4o\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 1. ë°ì´í„° ë¡œë“œ ë° ê²€ì¦\n",
    "    # ========================================================================================\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_FILE_PATH)\n",
    "        print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒ˜í”Œ\")\n",
    "        print(f\"ğŸ“‹ CSV ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    print(\"\\nğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "    for col in ['user_input', 'project_info', 'total_requirements', 'ERD_data']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(safe_parse_json_string)\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 2. 3ê°œ ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰\n",
    "    # ========================================================================================\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜ ì œí•œ\n",
    "    test_samples = min(5, len(df))\n",
    "    test_df = df.head(test_samples).copy()\n",
    "    \n",
    "    print(f\"\\nğŸ”„ {test_samples}ê°œ ìƒ˜í”Œì— ëŒ€í•´ 3ê°œ ëª¨ë¸ ì¶”ë¡  ì‹œì‘...\")\n",
    "    \n",
    "    # 3ê°œ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "    results = {\n",
    "        FINETUNED_MODEL: [],\n",
    "        BASELINE_MINI_MODEL: [],\n",
    "        BASELINE_4O_MODEL: []\n",
    "    }\n",
    "    \n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"ëª¨ë¸ ì¶”ë¡  ì§„í–‰\"):\n",
    "        user_input = row['user_input']\n",
    "        project_info = row['project_info']\n",
    "        \n",
    "        print(f\"\\nğŸ“ ìƒ˜í”Œ {idx+1} ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # 1. íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡ \n",
    "        print(f\"   ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸ ì¶”ë¡ ...\")\n",
    "        ft_result = openai_chat_completion(FINETUNED_MODEL, user_input, project_info)\n",
    "        results[FINETUNED_MODEL].append(ft_result)\n",
    "        \n",
    "        # 2. GPT-4o-mini ì›ë³¸ ì¶”ë¡ \n",
    "        print(f\"   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\")\n",
    "        mini_result = openai_chat_completion(BASELINE_MINI_MODEL, user_input, project_info)\n",
    "        results[BASELINE_MINI_MODEL].append(mini_result)\n",
    "        \n",
    "        # 3. GPT-4o ì¶”ë¡ \n",
    "        print(f\"   ğŸ”¥ GPT-4o ì¶”ë¡ ...\")\n",
    "        gpt4o_result = openai_chat_completion(BASELINE_4O_MODEL, user_input, project_info)\n",
    "        results[BASELINE_4O_MODEL].append(gpt4o_result)\n",
    "        \n",
    "        time.sleep(1.0)  # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë°©ì§€\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚° ë° ë¹„êµ\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ 3ê°œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ì •ë‹µ ë°ì´í„°\n",
    "    references = test_df['ERD_data'].tolist()\n",
    "    \n",
    "    # ëª¨ë¸ë³„ ì„±ëŠ¥ ê³„ì‚°\n",
    "    final_results = {}\n",
    "    model_names = {\n",
    "        FINETUNED_MODEL: \"íŒŒì¸íŠœë‹_ëª¨ë¸\",\n",
    "        BASELINE_MINI_MODEL: \"GPT-4o-mini\", \n",
    "        BASELINE_4O_MODEL: \"GPT-4o\"\n",
    "    }\n",
    "    \n",
    "    for model_id, predictions in results.items():\n",
    "        model_name = model_names[model_id]\n",
    "        \n",
    "        print(f\"\\nğŸ” {model_name} ì¶œë ¥ í™•ì¸:\")\n",
    "        for i, pred in enumerate(predictions[:2]):\n",
    "            print(f\"  ì¶œë ¥ {i+1}: {str(pred)[:150]}...\")\n",
    "        \n",
    "        metrics = calculate_metrics(predictions, references)\n",
    "        \n",
    "        print(f\"\\nğŸ¤– {model_name} ì„±ëŠ¥:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"   {metric_name}: {value}\")\n",
    "        \n",
    "        final_results[model_name] = metrics\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 4. ì¢…í•© ë¹„êµ ë¶„ì„\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì¢…í•© ì„±ëŠ¥ ë¹„êµ ë¶„ì„\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ì„±ëŠ¥ ë¹„êµ í‘œ ì¶œë ¥\n",
    "    metrics_list = [\"BLEU\", \"ROUGE-L\", \"ì˜ë¯¸ì _ìœ ì‚¬ë„(%)\"]\n",
    "    \n",
    "    print(f\"{'ë©”íŠ¸ë¦­':<15} {'íŒŒì¸íŠœë‹':<12} {'4o-mini':<12} {'GPT-4o':<12} {'vs mini':<12} {'vs 4o':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric in metrics_list:\n",
    "        ft_score = final_results[\"íŒŒì¸íŠœë‹_ëª¨ë¸\"][metric]\n",
    "        mini_score = final_results[\"GPT-4o-mini\"][metric]\n",
    "        gpt4o_score = final_results[\"GPT-4o\"][metric]\n",
    "        \n",
    "        vs_mini = ft_score - mini_score\n",
    "        vs_4o = ft_score - gpt4o_score\n",
    "        \n",
    "        print(f\"{metric:<15} {ft_score:<12.2f} {mini_score:<12.2f} {gpt4o_score:<12.2f} {vs_mini:<+12.2f} {vs_4o:<+12.2f}\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 5. íŒŒì¸íŠœë‹ íš¨ê³¼ ë¶„ì„\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ¯ íŒŒì¸íŠœë‹ íš¨ê³¼ ë¶„ì„\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    ft_metrics = final_results[\"íŒŒì¸íŠœë‹_ëª¨ë¸\"]\n",
    "    mini_metrics = final_results[\"GPT-4o-mini\"]\n",
    "    gpt4o_metrics = final_results[\"GPT-4o\"]\n",
    "    \n",
    "    # ë² ì´ìŠ¤ ëª¨ë¸(4o-mini) ëŒ€ë¹„ ê°œì„ ë„\n",
    "    print(\"ğŸ“ˆ ë² ì´ìŠ¤ ëª¨ë¸(GPT-4o-mini) ëŒ€ë¹„ íŒŒì¸íŠœë‹ ê°œì„ ë„:\")\n",
    "    mini_improvements = 0\n",
    "    for metric in metrics_list:\n",
    "        diff = ft_metrics[metric] - mini_metrics[metric]\n",
    "        improvement_rate = (diff / mini_metrics[metric]) * 100 if mini_metrics[metric] != 0 else 0\n",
    "        print(f\"  {metric}: {diff:+.2f} ({improvement_rate:+.1f}%)\")\n",
    "        if diff > 0:\n",
    "            mini_improvements += 1\n",
    "    \n",
    "    # í”Œë˜ê·¸ì‹­ ëª¨ë¸(GPT-4o) ëŒ€ë¹„ ì„±ëŠ¥\n",
    "    print(f\"\\nğŸ”¥ í”Œë˜ê·¸ì‹­ ëª¨ë¸(GPT-4o) ëŒ€ë¹„ íŒŒì¸íŠœë‹ ì„±ëŠ¥:\")\n",
    "    gpt4o_wins = 0\n",
    "    for metric in metrics_list:\n",
    "        diff = ft_metrics[metric] - gpt4o_metrics[metric]\n",
    "        print(f\"  {metric}: {diff:+.2f} ({'ìš°ìˆ˜' if diff > 0 else 'ì—´ì„¸'})\")\n",
    "        if diff > 0:\n",
    "            gpt4o_wins += 1\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 6. ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ† ìµœì¢… ê²°ë¡ \")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if mini_improvements >= 2:\n",
    "        print(\"âœ… íŒŒì¸íŠœë‹ì´ ë² ì´ìŠ¤ ëª¨ë¸ ëŒ€ë¹„ ëª…í™•í•œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ íŒŒì¸íŠœë‹ íš¨ê³¼ê°€ ì œí•œì ì…ë‹ˆë‹¤.\")\n",
    "    \n",
    "    if gpt4o_wins >= 2:\n",
    "        print(\"ğŸ”¥ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ í”Œë˜ê·¸ì‹­ ëª¨ë¸ë„ ëŠ¥ê°€í•˜ëŠ” ë†€ë¼ìš´ ì„±ê³¼ì…ë‹ˆë‹¤!\")\n",
    "    elif gpt4o_wins >= 1:\n",
    "        print(\"ğŸ‘ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì¼ë¶€ ì§€í‘œì—ì„œ í”Œë˜ê·¸ì‹­ ëª¨ë¸ê³¼ ê²½ìŸí•©ë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(\"ğŸ“ í”Œë˜ê·¸ì‹­ ëª¨ë¸ ëŒ€ë¹„ë¡œëŠ” ì•„ì§ ê°œì„  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„\n",
    "    print(f\"\\nğŸ’° ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„:\")\n",
    "    print(f\"  íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„ìš©: GPT-4oì˜ ~10% (í›¨ì”¬ ì €ë ´)\")\n",
    "    print(f\"  ì¶”ë¡  ì†ë„: GPT-4oë³´ë‹¤ ë¹ ë¦„\")\n",
    "    if gpt4o_wins >= 1:\n",
    "        print(f\"  ì„±ëŠ¥: ì¼ë¶€ ì§€í‘œì—ì„œ GPT-4o ìˆ˜ì¤€ ë˜ëŠ” ê·¸ ì´ìƒ\")\n",
    "        print(f\"  â†’ ğŸ¯ ë§¤ìš° ë†’ì€ ROI!\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 7. ê²°ê³¼ ì €ì¥\n",
    "    # ========================================================================================\n",
    "    \n",
    "    try:\n",
    "        with open(\"3ëª¨ë¸_ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(final_results, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"\\nğŸ’¾ ê²°ê³¼ê°€ '3ëª¨ë¸_ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ========================================================================================\n",
    "# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„\n",
    "# ========================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"ğŸš€ 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {CSV_FILE_PATH}\")\n",
    "    print(f\"ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸: {FINETUNED_MODEL}\")\n",
    "    print(f\"ğŸ¤– GPT-4o-mini: {BASELINE_MINI_MODEL}\")\n",
    "    print(f\"ğŸ”¥ GPT-4o: {BASELINE_4O_MODEL}\")\n",
    "    print(f\"ğŸŒ¡ï¸ ì˜¨ë„ ì„¤ì •: {TEMPERATURE}\")\n",
    "    \n",
    "    run_three_model_evaluation()\n",
    "    \n",
    "    print(\"\\nâœ… 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64a98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ëª¨ë¸_ì¶œë ¥_ë¹„êµ_ê°œì„ .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d821bac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>total_requirements</th>\n",
       "      <th>project_info</th>\n",
       "      <th>ERD_data</th>\n",
       "      <th>íŒŒì¸íŠœë‹_ëª¨ë¸_ì¶œë ¥</th>\n",
       "      <th>GPT4o_ì¶œë ¥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'projectName': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', 'projectTa...</td>\n",
       "      <td>[{'requirementType': 'FUNCTIONAL', 'content': ...</td>\n",
       "      <td>{'project_info': {'title': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', ...</td>\n",
       "      <td>{'erd_tables': [{'name': 'users', 'erd_columns...</td>\n",
       "      <td>ì•„ë˜ëŠ” \"ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬\" í”„ë¡œì íŠ¸ì— ëŒ€í•œ ERD(Entity Rela...</td>\n",
       "      <td>ì•„ë˜ëŠ” \"ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬\" í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ERD ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'projectName': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'projectTarget': 'ì¹˜...</td>\n",
       "      <td>[{'requirementType': 'FUNCTIONAL', 'content': ...</td>\n",
       "      <td>{'project_info': {'title': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'category...</td>\n",
       "      <td>{'erd_tables': [{'name': 'Users', 'erd_columns...</td>\n",
       "      <td>ì•„ë˜ëŠ” \"ê¸°ì–µì˜ ë‹¤ë¦¬\" í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ERD(Entity Relationship ...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'projectName': 'ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±', 'projectT...</td>\n",
       "      <td>[{'requirementType': 'FUNCTIONAL', 'content': ...</td>\n",
       "      <td>{'project_info': {'title': 'ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±',...</td>\n",
       "      <td>{'erd_tables': [{'name': 'Users', 'erd_columns...</td>\n",
       "      <td>ì•„ë˜ëŠ” \"ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±\"ì˜ ERD(Entity Relationshi...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'projectName': 'ê°€ìƒ í”¼íŒ…ë£¸ ì„œë¹„ìŠ¤', 'projectTarget'...</td>\n",
       "      <td>[{'requirementType': 'FUNCTIONAL', 'content': ...</td>\n",
       "      <td>{'project_info': {'title': 'ê°€ìƒ í”¼íŒ…ë£¸ ì„œë¹„ìŠ¤', 'cate...</td>\n",
       "      <td>{'erd_tables': [{'name': 'ì‚¬ìš©ì', 'erd_columns':...</td>\n",
       "      <td>ì•„ë˜ëŠ” \"ê°€ìƒ í”¼íŒ…ë£¸ ì„œë¹„ìŠ¤\"ë¥¼ ìœ„í•œ ERD(Entity Relationship D...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'projectName': 'ìŠ¤ë§ˆíŠ¸ ê±´ê°• ê´€ë¦¬ ë¹„ì„œ', 'projectTarge...</td>\n",
       "      <td>[{'requirementType': 'FUNCTIONAL', 'content': ...</td>\n",
       "      <td>{'project_info': {'title': 'ìŠ¤ë§ˆíŠ¸ ê±´ê°• ê´€ë¦¬ ë¹„ì„œ', 'ca...</td>\n",
       "      <td>{'erd_tables': [{'name': 'Users', 'erd_columns...</td>\n",
       "      <td>ì•„ë˜ëŠ” \"ìŠ¤ë§ˆíŠ¸ ê±´ê°• ê´€ë¦¬ ë¹„ì„œ\" í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ERD(Entity Relatio...</td>\n",
       "      <td>```json\\n{\\n  \"entities\": [\\n    {\\n      \"nam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  [{'projectName': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', 'projectTa...   \n",
       "1  [{'projectName': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'projectTarget': 'ì¹˜...   \n",
       "2  [{'projectName': 'ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±', 'projectT...   \n",
       "3  [{'projectName': 'ê°€ìƒ í”¼íŒ…ë£¸ ì„œë¹„ìŠ¤', 'projectTarget'...   \n",
       "4  [{'projectName': 'ìŠ¤ë§ˆíŠ¸ ê±´ê°• ê´€ë¦¬ ë¹„ì„œ', 'projectTarge...   \n",
       "\n",
       "                                  total_requirements  \\\n",
       "0  [{'requirementType': 'FUNCTIONAL', 'content': ...   \n",
       "1  [{'requirementType': 'FUNCTIONAL', 'content': ...   \n",
       "2  [{'requirementType': 'FUNCTIONAL', 'content': ...   \n",
       "3  [{'requirementType': 'FUNCTIONAL', 'content': ...   \n",
       "4  [{'requirementType': 'FUNCTIONAL', 'content': ...   \n",
       "\n",
       "                                        project_info  \\\n",
       "0  {'project_info': {'title': 'ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬', ...   \n",
       "1  {'project_info': {'title': 'ê¸°ì–µì˜ ë‹¤ë¦¬', 'category...   \n",
       "2  {'project_info': {'title': 'ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±',...   \n",
       "3  {'project_info': {'title': 'ê°€ìƒ í”¼íŒ…ë£¸ ì„œë¹„ìŠ¤', 'cate...   \n",
       "4  {'project_info': {'title': 'ìŠ¤ë§ˆíŠ¸ ê±´ê°• ê´€ë¦¬ ë¹„ì„œ', 'ca...   \n",
       "\n",
       "                                            ERD_data  \\\n",
       "0  {'erd_tables': [{'name': 'users', 'erd_columns...   \n",
       "1  {'erd_tables': [{'name': 'Users', 'erd_columns...   \n",
       "2  {'erd_tables': [{'name': 'Users', 'erd_columns...   \n",
       "3  {'erd_tables': [{'name': 'ì‚¬ìš©ì', 'erd_columns':...   \n",
       "4  {'erd_tables': [{'name': 'Users', 'erd_columns...   \n",
       "\n",
       "                                          íŒŒì¸íŠœë‹_ëª¨ë¸_ì¶œë ¥  \\\n",
       "0  ì•„ë˜ëŠ” \"ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬\" í”„ë¡œì íŠ¸ì— ëŒ€í•œ ERD(Entity Rela...   \n",
       "1  ì•„ë˜ëŠ” \"ê¸°ì–µì˜ ë‹¤ë¦¬\" í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ERD(Entity Relationship ...   \n",
       "2  ì•„ë˜ëŠ” \"ì¥ì• ì¸ ì¹œí™” ëŒ€ì¤‘êµí†µ ì•ˆë‚´ ì•±\"ì˜ ERD(Entity Relationshi...   \n",
       "3  ì•„ë˜ëŠ” \"ê°€ìƒ í”¼íŒ…ë£¸ ì„œë¹„ìŠ¤\"ë¥¼ ìœ„í•œ ERD(Entity Relationship D...   \n",
       "4  ì•„ë˜ëŠ” \"ìŠ¤ë§ˆíŠ¸ ê±´ê°• ê´€ë¦¬ ë¹„ì„œ\" í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ERD(Entity Relatio...   \n",
       "\n",
       "                                            GPT4o_ì¶œë ¥  \n",
       "0  ì•„ë˜ëŠ” \"ìŠ¤í„°ë”” ê·¸ë£¹ ì„±ê³¼ ë¶„ì„ ë„êµ¬\" í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ERD ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°...  \n",
       "1  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"nam...  \n",
       "2  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"nam...  \n",
       "3  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"nam...  \n",
       "4  ```json\\n{\\n  \"entities\": [\\n    {\\n      \"nam...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30517074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ERD íŠ¹í™” 3ëª¨ë¸ ì„±ëŠ¥ ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: hehe.csv\n",
      "ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸: ft:gpt-4o-mini-2024-07-18:test:pja-api-finetuning-model:BmOdcDUE\n",
      "ğŸ¤– GPT-4o-mini: gpt-4o-mini\n",
      "ğŸ”¥ GPT-4o: gpt-4o\n",
      "ğŸŒ¡ï¸ ì˜¨ë„ ì„¤ì •: 0.2\n",
      "ğŸ“Š í‰ê°€ ë°©ì‹: ERD êµ¬ì¡°ì  í’ˆì§ˆ ë° ì •í™•ì„± ì¤‘ì‹¬\n",
      "ğŸ¯ ERD íŠ¹í™” 3ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: êµ¬ì¡°ì  í’ˆì§ˆê³¼ ì •í™•ì„± ì¤‘ì‹¬ í‰ê°€\n",
      "================================================================================\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 138ê°œ ìƒ˜í”Œ\n",
      "ğŸ“‹ CSV ì»¬ëŸ¼: ['user_input', 'total_requirements', 'project_info', 'ERD_data']\n",
      "\n",
      "ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "ğŸ”„ 5ê°œ ìƒ˜í”Œì— ëŒ€í•´ 3ê°œ ëª¨ë¸ ERD ìƒì„± ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 1 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹_ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  20%|â–ˆâ–ˆ        | 1/5 [00:51<03:25, 51.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 2 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹_ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:48<02:44, 54.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 3 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹_ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [02:37<01:44, 52.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 4 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹_ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [03:33<00:53, 53.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ìƒ˜í”Œ 5 ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¯ íŒŒì¸íŠœë‹_ëª¨ë¸ ì¶”ë¡ ...\n",
      "   ğŸ¤– GPT-4o-mini ì¶”ë¡ ...\n",
      "   ğŸ”¥ GPT-4o ì¶”ë¡ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì¶”ë¡  ì§„í–‰: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [04:27<00:00, 53.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ERD íŠ¹í™” í‰ê°€ ê²°ê³¼ ë¶„ì„\n",
      "================================================================================\n",
      "\n",
      "ğŸ” íŒŒì¸íŠœë‹_ëª¨ë¸ ë¶„ì„ ì¤‘...\n",
      "   JSON íŒŒì‹± ì„±ê³µë¥ : 100.0%\n",
      "   í‰ê·  í…Œì´ë¸” ìˆ˜: 5.6\n",
      "   ì„¤ê³„ í’ˆì§ˆ ì ìˆ˜: 93.4%\n",
      "   ì „ì²´ êµ¬ì¡° ì¼ì¹˜ë„: 12.5%\n",
      "\n",
      "ğŸ” GPT-4o-mini ë¶„ì„ ì¤‘...\n",
      "   JSON íŒŒì‹± ì„±ê³µë¥ : 100.0%\n",
      "   í‰ê·  í…Œì´ë¸” ìˆ˜: 5.0\n",
      "   ì„¤ê³„ í’ˆì§ˆ ì ìˆ˜: 99.7%\n",
      "   ì „ì²´ êµ¬ì¡° ì¼ì¹˜ë„: 13.2%\n",
      "\n",
      "ğŸ” GPT-4o ë¶„ì„ ì¤‘...\n",
      "   JSON íŒŒì‹± ì„±ê³µë¥ : 100.0%\n",
      "   í‰ê·  í…Œì´ë¸” ìˆ˜: 5.0\n",
      "   ì„¤ê³„ í’ˆì§ˆ ì ìˆ˜: 100.0%\n",
      "   ì „ì²´ êµ¬ì¡° ì¼ì¹˜ë„: 16.2%\n",
      "\n",
      "ğŸ“ˆ ERD íŠ¹í™” ì„±ëŠ¥ ë¹„êµ ë¶„ì„\n",
      "====================================================================================================\n",
      "ë©”íŠ¸ë¦­                  íŒŒì¸íŠœë‹         4o-mini      GPT-4o       vs mini      vs 4o       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "JSON_íŒŒì‹±_ì„±ê³µë¥ (%)       100.0        100.0        100.0        +0.0         +0.0        \n",
      "ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%)           93.4         99.7         100.0        -6.3         -6.6        \n",
      "ì „ì²´êµ¬ì¡°_ì¼ì¹˜ë„(%)          12.5         13.2         16.2         -0.7         -3.7        \n",
      "ê´€ê³„_ì¼ê´€ì„±(%)            100.0        95.0         100.0        +5.0         +0.0        \n",
      "ì™„ì„±ë„_ì ìˆ˜(%)            100.0        100.0        100.0        +0.0         +0.0        \n",
      "\n",
      "ğŸ” ì„¸ë¶€ ERD í’ˆì§ˆ ë¶„ì„\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š êµ¬ì¡°ì  í’ˆì§ˆ ë¶„ì„:\n",
      "  í‰ê· _í…Œì´ë¸”_ìˆ˜: íŒŒì¸íŠœë‹=5.6, 4o-mini=5.0, GPT-4o=5.0\n",
      "  í‰ê· _ê´€ê³„_ìˆ˜: íŒŒì¸íŠœë‹=5.0, 4o-mini=4.4, GPT-4o=4.2\n",
      "  í‰ê· _ì»¬ëŸ¼_ìˆ˜: íŒŒì¸íŠœë‹=17.6, 4o-mini=18.6, GPT-4o=21.6\n",
      "\n",
      "ğŸ”— ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ë¶„ì„:\n",
      "  ì™¸ë˜í‚¤_ì¼ê´€ì„±(%): íŒŒì¸íŠœë‹=60.0%, 4o-mini=95.0%, GPT-4o=95.0%\n",
      "  ê´€ê³„_ì¼ê´€ì„±(%): íŒŒì¸íŠœë‹=100.0%, 4o-mini=95.0%, GPT-4o=100.0%\n",
      "  ë„¤ì´ë°_ì¼ê´€ì„±(%): íŒŒì¸íŠœë‹=20.0%, 4o-mini=96.0%, GPT-4o=96.4%\n",
      "\n",
      "ğŸ¯ êµ¬ì¡° ì •í™•ì„± ë¶„ì„:\n",
      "  í…Œì´ë¸”ëª…_ì¼ì¹˜ë„(%): íŒŒì¸íŠœë‹=16.0%, 4o-mini=16.0%, GPT-4o=24.0%\n",
      "  ì»¬ëŸ¼êµ¬ì¡°_ì¼ì¹˜ë„(%): íŒŒì¸íŠœë‹=11.2%, 4o-mini=12.1%, GPT-4o=16.4%\n",
      "  ê´€ê³„êµ¬ì¡°_ì¼ì¹˜ë„(%): íŒŒì¸íŠœë‹=8.0%, 4o-mini=10.0%, GPT-4o=0.0%\n",
      "\n",
      "ğŸ¯ íŒŒì¸íŠœë‹ íš¨ê³¼ ì‹¬ì¸µ ë¶„ì„\n",
      "================================================================================\n",
      "ğŸ“ˆ ë² ì´ìŠ¤ ëª¨ë¸(GPT-4o-mini) ëŒ€ë¹„ íŒŒì¸íŠœë‹ ê°œì„ ë„:\n",
      "  JSON_íŒŒì‹±_ì„±ê³µë¥ (%): +0.0 (+0.0%)\n",
      "  ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%): -6.3 (-6.3%)\n",
      "  ì „ì²´êµ¬ì¡°_ì¼ì¹˜ë„(%): -0.7 (-5.5%)\n",
      "  ê´€ê³„_ì¼ê´€ì„±(%): +5.0 (+5.3%)\n",
      "  ì™„ì„±ë„_ì ìˆ˜(%): +0.0 (+0.0%)\n",
      "\n",
      "ğŸ”¥ í”Œë˜ê·¸ì‹­ ëª¨ë¸(GPT-4o) ëŒ€ë¹„ íŒŒì¸íŠœë‹ ì„±ëŠ¥:\n",
      "  JSON_íŒŒì‹±_ì„±ê³µë¥ (%): +0.0 (ğŸŸ¡ ë™ë“±)\n",
      "  ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%): -6.6 (ğŸ”´ ì—´ì„¸)\n",
      "  ì „ì²´êµ¬ì¡°_ì¼ì¹˜ë„(%): -3.7 (ğŸ”´ ì—´ì„¸)\n",
      "  ê´€ê³„_ì¼ê´€ì„±(%): +0.0 (ğŸŸ¡ ë™ë“±)\n",
      "  ì™„ì„±ë„_ì ìˆ˜(%): +0.0 (ğŸŸ¡ ë™ë“±)\n",
      "\n",
      "âš¡ ëª¨ë¸ë³„ ê°•ì  ë¶„ì„\n",
      "================================================================================\n",
      "\n",
      "ğŸ† íŒŒì¸íŠœë‹_ëª¨ë¸ ìµœìš°ìˆ˜ ì˜ì—­:\n",
      "  â€¢ JSON_íŒŒì‹±_ì„±ê³µë¥ (%): 100.0\n",
      "  â€¢ í‰ê· _í…Œì´ë¸”_ìˆ˜: 5.6\n",
      "  â€¢ í‰ê· _ê´€ê³„_ìˆ˜: 5.0\n",
      "  â€¢ ê´€ê³„_ì¼ê´€ì„±(%): 100.0\n",
      "  â€¢ ì™„ì„±ë„_ì ìˆ˜(%): 100.0\n",
      "\n",
      "ğŸ† GPT-4o-mini ìµœìš°ìˆ˜ ì˜ì—­:\n",
      "  â€¢ ì™¸ë˜í‚¤_ì¼ê´€ì„±(%): 95.0\n",
      "  â€¢ ì •ê·œí™”_ì ìˆ˜(%): 100.0\n",
      "  â€¢ ê´€ê³„êµ¬ì¡°_ì¼ì¹˜ë„(%): 10.0\n",
      "\n",
      "ğŸ† GPT-4o ìµœìš°ìˆ˜ ì˜ì—­:\n",
      "  â€¢ í‰ê· _ì»¬ëŸ¼_ìˆ˜: 21.6\n",
      "  â€¢ ë„¤ì´ë°_ì¼ê´€ì„±(%): 96.4\n",
      "  â€¢ ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%): 100.0\n",
      "  â€¢ í…Œì´ë¸”ëª…_ì¼ì¹˜ë„(%): 24.0\n",
      "  â€¢ ì»¬ëŸ¼êµ¬ì¡°_ì¼ì¹˜ë„(%): 16.4\n",
      "\n",
      "ğŸ’¼ ì‹¤ìš©ì„± í‰ê°€\n",
      "================================================================================\n",
      "ğŸ”§ JSON ìƒì„± ì•ˆì •ì„±:\n",
      "  íŒŒì¸íŠœë‹: 100.0% (ğŸŸ¢ ë§¤ìš°ì•ˆì •)\n",
      "  4o-mini: 100.0% (ğŸŸ¢ ë§¤ìš°ì•ˆì •)\n",
      "  GPT-4o: 100.0% (ğŸŸ¢ ë§¤ìš°ì•ˆì •)\n",
      "\n",
      "ğŸ¨ ERD ì„¤ê³„ í’ˆì§ˆ:\n",
      "  íŒŒì¸íŠœë‹: 93.4% (ğŸŸ¢ ìš°ìˆ˜)\n",
      "  4o-mini: 99.7% (ğŸŸ¢ ìš°ìˆ˜)\n",
      "  GPT-4o: 100.0% (ğŸŸ¢ ìš°ìˆ˜)\n",
      "\n",
      "ğŸ† ìµœì¢… ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\n",
      "================================================================================\n",
      "ğŸ“Š íŒŒì¸íŠœë‹ íš¨ê³¼: ğŸ”´ íŒŒì¸íŠœë‹ íš¨ê³¼ ì œí•œì . ì¶”ê°€ ìµœì í™” í•„ìš”\n",
      "   â€¢ 1/5 ì£¼ìš” ë©”íŠ¸ë¦­ì—ì„œ ê°œì„ \n",
      "   â€¢ í‰ê·  ê°œì„ ìœ¨: -1.3%\n",
      "\n",
      "ğŸ¯ GPT-4o ëŒ€ë¹„: ğŸ“ˆ í”Œë˜ê·¸ì‹­ ëª¨ë¸ ëŒ€ë¹„ ê°œì„  ì—¬ì§€ ì¡´ì¬\n",
      "   â€¢ 0/5 ì£¼ìš” ë©”íŠ¸ë¦­ì—ì„œ ìš°ì„¸\n",
      "\n",
      "ğŸ’¡ ì‹¤ìš©ì  ê¶Œì¥ì‚¬í•­:\n",
      "  ğŸ”¥ GPT-4o ì‚¬ìš© ê¶Œì¥:\n",
      "    - ìµœê³  í’ˆì§ˆì˜ ERD ì„¤ê³„\n",
      "    - ë³µì¡í•œ ìš”êµ¬ì‚¬í•­ ì²˜ë¦¬ ìš°ìˆ˜\n",
      "    - ë†’ì€ ì¼ê´€ì„±\n",
      "\n",
      "ğŸ’° ë¹„ìš© ëŒ€ë¹„ ì„±ëŠ¥ ë¶„ì„:\n",
      "  íŒŒì¸íŠœë‹ ëª¨ë¸: ì„±ëŠ¥ 81.2, ë¹„ìš© â­\n",
      "  GPT-4o-mini: ì„±ëŠ¥ 81.6, ë¹„ìš© â­â­\n",
      "  GPT-4o: ì„±ëŠ¥ 83.2, ë¹„ìš© â­â­â­â­â­\n",
      "  ğŸ’ ìµœê³  ROI: íŒŒì¸íŠœë‹ (ë¹„ìš©íš¨ìœ¨ì ìˆ˜: 405.9)\n",
      "\n",
      "ğŸ’¾ ìƒì„¸ ê²°ê³¼ê°€ 'ERDíŠ¹í™”_3ëª¨ë¸_ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“„ ìš”ì•½ ë¦¬í¬íŠ¸ê°€ 'ERDíŠ¹í™”_ì„±ëŠ¥ë¹„êµ_ìš”ì•½.txt' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "âœ… ERD íŠ¹í™” 3ëª¨ë¸ ì„±ëŠ¥ ë¹„êµê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ“‹ ê²°ê³¼ íŒŒì¼:\n",
      "   â€¢ ERDíŠ¹í™”_3ëª¨ë¸_ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json (ìƒì„¸ ê²°ê³¼)\n",
      "   â€¢ ERDíŠ¹í™”_ì„±ëŠ¥ë¹„êµ_ìš”ì•½.txt (ìš”ì•½ ë¦¬í¬íŠ¸)\n",
      "\n",
      "ğŸ¯ ì´ì œ ERD ì„¤ê³„ì— ìµœì í™”ëœ í‰ê°€ë¡œ ì •í™•í•œ ëª¨ë¸ ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ERD íŠ¹í™” 3ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: êµ¬ì¡°ì  í’ˆì§ˆê³¼ ì •í™•ì„± ì¤‘ì‹¬ í‰ê°€\n",
    "JSON êµ¬ì¡°, ìŠ¤í‚¤ë§ˆ ì •í™•ì„±, ERD ì„¤ê³„ í’ˆì§ˆì„ ì§ì ‘ ì¸¡ì •í•˜ëŠ” ì „ë¬¸ í‰ê°€ ì‹œìŠ¤í…œ\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# ========================================================================================\n",
    "# ì „ì—­ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜\n",
    "# ========================================================================================\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  3ê°œ ëª¨ë¸ ì •ì˜\n",
    "FINETUNED_MODEL = \"ft:gpt-4o-mini-2024-07-18:test:pja-api-finetuning-model:BmOdcDUE\"\n",
    "BASELINE_MINI_MODEL = \"gpt-4o-mini\"\n",
    "BASELINE_4O_MODEL = \"gpt-4o\"\n",
    "\n",
    "# API í˜¸ì¶œ ì„¤ì •\n",
    "TEMPERATURE = 0.2\n",
    "CSV_FILE_PATH = \"hehe.csv\"\n",
    "\n",
    "# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "ë‹¹ì‹ ì€ ERD ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ì™„ì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "**í•µì‹¬ ì›ì¹™:**\n",
    "- ë°±ìŠ¬ë˜ì‹œ(\\\\) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€\n",
    "- erd_relationshipsì˜ ëª¨ë“  í…Œì´ë¸”ê³¼ ì™¸ë˜í‚¤ëŠ” ë°˜ë“œì‹œ erd_tablesì— ì¡´ì¬í•´ì•¼ í•¨\n",
    "- ì™¸ë˜í‚¤ ì»¬ëŸ¼ì€ is_foreign_key: true ì„¤ì • í•„ìˆ˜\n",
    "- ìˆœìˆ˜ JSONë§Œ ì‘ë‹µ (ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ê¸ˆì§€)\n",
    "**ì„¤ê³„ ìˆœì„œ:**\n",
    "1. ì—”í‹°í‹° ì‹ë³„ â†’ 2. ì†ì„±/ê¸°ë³¸í‚¤ ì •ì˜ â†’ 3. ê´€ê³„ ë¶„ì„/ì™¸ë˜í‚¤ ì¶”ê°€ â†’ 4. ê´€ê³„ ì •ë³´ ì‘ì„±\n",
    "**ì¤‘ìš”: ëª¨ë“  ê´€ê³„ì˜ í…Œì´ë¸”ëª…ê³¼ ì™¸ë˜í‚¤ê°€ í…Œì´ë¸” ì •ì˜ì™€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.**\n",
    "\"\"\"\n",
    "\n",
    "# ========================================================================================\n",
    "# ERD íŠ¹í™” í‰ê°€ í•¨ìˆ˜ë“¤\n",
    "# ========================================================================================\n",
    "\n",
    "def safe_parse_json(json_str: str) -> Tuple[Dict, bool]:\n",
    "    \"\"\"JSON íŒŒì‹±ì„ ì‹œë„í•˜ê³  ì„±ê³µ ì—¬ë¶€ë¥¼ ë°˜í™˜\"\"\"\n",
    "    if pd.isna(json_str) or json_str == '':\n",
    "        return {}, False\n",
    "    \n",
    "    try:\n",
    "        if isinstance(json_str, (dict, list)):\n",
    "            return json_str, True\n",
    "        \n",
    "        if isinstance(json_str, str):\n",
    "            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°\n",
    "            json_str = re.sub(r'```json\\s*|\\s*```', '', json_str.strip())\n",
    "            json_str = json_str.strip()\n",
    "            \n",
    "            try:\n",
    "                return json.loads(json_str), True\n",
    "            except:\n",
    "                return ast.literal_eval(json_str), True\n",
    "    except Exception as e:\n",
    "        return {}, False\n",
    "\n",
    "def validate_erd_structure(erd_data: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"ERD JSON êµ¬ì¡°ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬\"\"\"\n",
    "    validation_result = {\n",
    "        'is_valid_json': True,\n",
    "        'has_erd_tables': False,\n",
    "        'has_erd_relationships': False,\n",
    "        'table_count': 0,\n",
    "        'relationship_count': 0,\n",
    "        'column_count': 0,\n",
    "        'foreign_key_count': 0,\n",
    "        'primary_key_count': 0,\n",
    "        'structural_issues': []\n",
    "    }\n",
    "    \n",
    "    if not isinstance(erd_data, dict):\n",
    "        validation_result['is_valid_json'] = False\n",
    "        validation_result['structural_issues'].append(\"Invalid JSON structure\")\n",
    "        return validation_result\n",
    "    \n",
    "    # í•„ìˆ˜ í‚¤ ì¡´ì¬ í™•ì¸\n",
    "    if 'erd_tables' in erd_data:\n",
    "        validation_result['has_erd_tables'] = True\n",
    "        tables = erd_data['erd_tables']\n",
    "        if isinstance(tables, list):\n",
    "            validation_result['table_count'] = len(tables)\n",
    "            \n",
    "            # í…Œì´ë¸”ë³„ ì»¬ëŸ¼ ë¶„ì„\n",
    "            for table in tables:\n",
    "                if isinstance(table, dict) and 'erd_columns' in table:\n",
    "                    columns = table['erd_columns']\n",
    "                    if isinstance(columns, list):\n",
    "                        validation_result['column_count'] += len(columns)\n",
    "                        \n",
    "                        for col in columns:\n",
    "                            if isinstance(col, dict):\n",
    "                                if col.get('is_foreign_key', False):\n",
    "                                    validation_result['foreign_key_count'] += 1\n",
    "                                if col.get('is_primary_key', False):\n",
    "                                    validation_result['primary_key_count'] += 1\n",
    "        else:\n",
    "            validation_result['structural_issues'].append(\"erd_tables is not a list\")\n",
    "    else:\n",
    "        validation_result['structural_issues'].append(\"Missing erd_tables\")\n",
    "    \n",
    "    if 'erd_relationships' in erd_data:\n",
    "        validation_result['has_erd_relationships'] = True\n",
    "        relationships = erd_data['erd_relationships']\n",
    "        if isinstance(relationships, list):\n",
    "            validation_result['relationship_count'] = len(relationships)\n",
    "        else:\n",
    "            validation_result['structural_issues'].append(\"erd_relationships is not a list\")\n",
    "    else:\n",
    "        validation_result['structural_issues'].append(\"Missing erd_relationships\")\n",
    "    \n",
    "    return validation_result\n",
    "\n",
    "def calculate_schema_consistency(erd_data: Dict) -> Dict[str, float]:\n",
    "    \"\"\"ERD ìŠ¤í‚¤ë§ˆì˜ ì¼ê´€ì„±ì„ ê³„ì‚°\"\"\"\n",
    "    consistency_metrics = {\n",
    "        'foreign_key_consistency': 0.0,  # ì™¸ë˜í‚¤ê°€ ì‹¤ì œ í…Œì´ë¸”ì— ì¡´ì¬í•˜ëŠ”ê°€\n",
    "        'relationship_consistency': 0.0,  # ê´€ê³„ì˜ í…Œì´ë¸”ë“¤ì´ ì‹¤ì œ ì¡´ì¬í•˜ëŠ”ê°€\n",
    "        'data_type_consistency': 0.0,    # ë°ì´í„° íƒ€ì…ì´ ì¼ê´€ë˜ê²Œ ì •ì˜ë˜ì—ˆëŠ”ê°€\n",
    "        'naming_consistency': 0.0        # ë„¤ì´ë° ê·œì¹™ì´ ì¼ê´€ë˜ëŠ”ê°€\n",
    "    }\n",
    "    \n",
    "    if not isinstance(erd_data, dict):\n",
    "        return consistency_metrics\n",
    "    \n",
    "    tables = erd_data.get('erd_tables', [])\n",
    "    relationships = erd_data.get('erd_relationships', [])\n",
    "    \n",
    "    if not tables:\n",
    "        return consistency_metrics\n",
    "    \n",
    "    # í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘\n",
    "    table_names = set()\n",
    "    table_columns = {}\n",
    "    all_columns = []\n",
    "    \n",
    "    for table in tables:\n",
    "        if isinstance(table, dict) and 'name' in table:\n",
    "            table_name = table['name']\n",
    "            table_names.add(table_name)\n",
    "            \n",
    "            columns = table.get('erd_columns', [])\n",
    "            table_columns[table_name] = {}\n",
    "            \n",
    "            for col in columns:\n",
    "                if isinstance(col, dict) and 'name' in col:\n",
    "                    col_name = col['name']\n",
    "                    table_columns[table_name][col_name] = col\n",
    "                    all_columns.append(col)\n",
    "    \n",
    "    # 1. ì™¸ë˜í‚¤ ì¼ê´€ì„± ê²€ì‚¬\n",
    "    if all_columns:\n",
    "        foreign_keys = [col for col in all_columns if col.get('is_foreign_key', False)]\n",
    "        if foreign_keys:\n",
    "            valid_fk_count = 0\n",
    "            for fk in foreign_keys:\n",
    "                # ì™¸ë˜í‚¤ê°€ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ ê°„ì ‘ì ìœ¼ë¡œ í™•ì¸\n",
    "                # (ì‹¤ì œ ì°¸ì¡° í…Œì´ë¸” ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ì™¸ë˜í‚¤ ëª…ëª… ê·œì¹™ìœ¼ë¡œ ì¶”ì •)\n",
    "                fk_name = fk.get('name', '')\n",
    "                if '_id' in fk_name or 'id' in fk_name:\n",
    "                    valid_fk_count += 1\n",
    "            consistency_metrics['foreign_key_consistency'] = valid_fk_count / len(foreign_keys) * 100\n",
    "        else:\n",
    "            consistency_metrics['foreign_key_consistency'] = 100.0  # ì™¸ë˜í‚¤ê°€ ì—†ìœ¼ë©´ ë§Œì \n",
    "    \n",
    "    # 2. ê´€ê³„ ì¼ê´€ì„± ê²€ì‚¬\n",
    "    if relationships and table_names:\n",
    "        valid_relationship_count = 0\n",
    "        for rel in relationships:\n",
    "            if isinstance(rel, dict):\n",
    "                from_table = rel.get('from_table', '')\n",
    "                to_table = rel.get('to_table', '')\n",
    "                foreign_key = rel.get('foreign_key', '')\n",
    "                \n",
    "                # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "                tables_exist = from_table in table_names and to_table in table_names\n",
    "                \n",
    "                # ì™¸ë˜í‚¤ê°€ ì‹¤ì œ ì»¬ëŸ¼ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "                fk_exists = False\n",
    "                if from_table in table_columns:\n",
    "                    fk_exists = foreign_key in table_columns[from_table]\n",
    "                \n",
    "                if tables_exist and fk_exists:\n",
    "                    valid_relationship_count += 1\n",
    "        \n",
    "        consistency_metrics['relationship_consistency'] = valid_relationship_count / len(relationships) * 100\n",
    "    else:\n",
    "        consistency_metrics['relationship_consistency'] = 100.0 if not relationships else 0.0\n",
    "    \n",
    "    # 3. ë°ì´í„° íƒ€ì… ì¼ê´€ì„± (ê³µí†µ íƒ€ì…ë“¤ì´ ì¼ê´€ë˜ê²Œ ì‚¬ìš©ë˜ëŠ”ê°€)\n",
    "    if all_columns:\n",
    "        data_types = [col.get('data_type', '').lower() for col in all_columns if col.get('data_type')]\n",
    "        if data_types:\n",
    "            # í‘œì¤€ ë°ì´í„° íƒ€ì…ê³¼ì˜ ì¼ì¹˜ë„ ì¸¡ì •\n",
    "            standard_types = {'int', 'varchar', 'text', 'date', 'datetime', 'boolean', 'decimal', 'float'}\n",
    "            standard_type_count = sum(1 for dt in data_types if any(st in dt for st in standard_types))\n",
    "            consistency_metrics['data_type_consistency'] = standard_type_count / len(data_types) * 100\n",
    "        else:\n",
    "            consistency_metrics['data_type_consistency'] = 0.0\n",
    "    \n",
    "    # 4. ë„¤ì´ë° ì¼ê´€ì„± (snake_case ë“± ì¼ê´€ëœ ëª…ëª… ê·œì¹™)\n",
    "    all_names = list(table_names)\n",
    "    for cols in table_columns.values():\n",
    "        all_names.extend(cols.keys())\n",
    "    \n",
    "    if all_names:\n",
    "        snake_case_count = sum(1 for name in all_names if re.match(r'^[a-z][a-z0-9_]*$', name))\n",
    "        consistency_metrics['naming_consistency'] = snake_case_count / len(all_names) * 100\n",
    "    \n",
    "    return consistency_metrics\n",
    "\n",
    "def compare_erd_structures(pred_erd: Dict, ref_erd: Dict) -> Dict[str, float]:\n",
    "    \"\"\"ë‘ ERD êµ¬ì¡°ë¥¼ ë¹„êµí•˜ì—¬ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°\"\"\"\n",
    "    comparison_metrics = {\n",
    "        'table_name_similarity': 0.0,      # í…Œì´ë¸”ëª… ì¼ì¹˜ë„\n",
    "        'column_structure_similarity': 0.0, # ì»¬ëŸ¼ êµ¬ì¡° ìœ ì‚¬ë„\n",
    "        'relationship_similarity': 0.0,     # ê´€ê³„ êµ¬ì¡° ìœ ì‚¬ë„\n",
    "        'overall_structure_similarity': 0.0 # ì „ì²´ êµ¬ì¡° ìœ ì‚¬ë„\n",
    "    }\n",
    "    \n",
    "    # í…Œì´ë¸”ëª… ë¹„êµ\n",
    "    pred_tables = {table.get('name', '') for table in pred_erd.get('erd_tables', []) if isinstance(table, dict)}\n",
    "    ref_tables = {table.get('name', '') for table in ref_erd.get('erd_tables', []) if isinstance(table, dict)}\n",
    "    \n",
    "    if ref_tables:\n",
    "        table_intersection = pred_tables.intersection(ref_tables)\n",
    "        comparison_metrics['table_name_similarity'] = len(table_intersection) / len(ref_tables) * 100\n",
    "    \n",
    "    # ì»¬ëŸ¼ êµ¬ì¡° ë¹„êµ\n",
    "    pred_columns = set()\n",
    "    ref_columns = set()\n",
    "    \n",
    "    for table in pred_erd.get('erd_tables', []):\n",
    "        if isinstance(table, dict):\n",
    "            table_name = table.get('name', '')\n",
    "            for col in table.get('erd_columns', []):\n",
    "                if isinstance(col, dict):\n",
    "                    pred_columns.add(f\"{table_name}.{col.get('name', '')}\")\n",
    "    \n",
    "    for table in ref_erd.get('erd_tables', []):\n",
    "        if isinstance(table, dict):\n",
    "            table_name = table.get('name', '')\n",
    "            for col in table.get('erd_columns', []):\n",
    "                if isinstance(col, dict):\n",
    "                    ref_columns.add(f\"{table_name}.{col.get('name', '')}\")\n",
    "    \n",
    "    if ref_columns:\n",
    "        column_intersection = pred_columns.intersection(ref_columns)\n",
    "        comparison_metrics['column_structure_similarity'] = len(column_intersection) / len(ref_columns) * 100\n",
    "    \n",
    "    # ê´€ê³„ ë¹„êµ\n",
    "    pred_relationships = set()\n",
    "    ref_relationships = set()\n",
    "    \n",
    "    for rel in pred_erd.get('erd_relationships', []):\n",
    "        if isinstance(rel, dict):\n",
    "            rel_key = f\"{rel.get('from_table', '')}->{rel.get('to_table', '')}\"\n",
    "            pred_relationships.add(rel_key)\n",
    "    \n",
    "    for rel in ref_erd.get('erd_relationships', []):\n",
    "        if isinstance(rel, dict):\n",
    "            rel_key = f\"{rel.get('from_table', '')}->{rel.get('to_table', '')}\"\n",
    "            ref_relationships.add(rel_key)\n",
    "    \n",
    "    if ref_relationships:\n",
    "        rel_intersection = pred_relationships.intersection(ref_relationships)\n",
    "        comparison_metrics['relationship_similarity'] = len(rel_intersection) / len(ref_relationships) * 100\n",
    "    \n",
    "    # ì „ì²´ êµ¬ì¡° ìœ ì‚¬ë„ (ê°€ì¤‘ í‰ê· )\n",
    "    comparison_metrics['overall_structure_similarity'] = (\n",
    "        comparison_metrics['table_name_similarity'] * 0.4 +\n",
    "        comparison_metrics['column_structure_similarity'] * 0.4 +\n",
    "        comparison_metrics['relationship_similarity'] * 0.2\n",
    "    )\n",
    "    \n",
    "    return comparison_metrics\n",
    "\n",
    "def calculate_erd_quality_score(erd_data: Dict) -> Dict[str, float]:\n",
    "    \"\"\"ERD ì„¤ê³„ í’ˆì§ˆ ì ìˆ˜ë¥¼ ê³„ì‚°\"\"\"\n",
    "    quality_metrics = {\n",
    "        'completeness_score': 0.0,    # ì™„ì„±ë„ (í•„ìˆ˜ ìš”ì†Œ í¬í•¨ ì—¬ë¶€)\n",
    "        'complexity_score': 0.0,      # ë³µì¡ë„ (ì ì ˆí•œ í…Œì´ë¸”/ê´€ê³„ ìˆ˜)\n",
    "        'normalization_score': 0.0,   # ì •ê·œí™” ì ìˆ˜ (ê¸°ë³¸í‚¤/ì™¸ë˜í‚¤ ì ì ˆì„±)\n",
    "        'design_quality_score': 0.0   # ì„¤ê³„ í’ˆì§ˆ ì¢…í•© ì ìˆ˜\n",
    "    }\n",
    "    \n",
    "    validation = validate_erd_structure(erd_data)\n",
    "    \n",
    "    # 1. ì™„ì„±ë„ ì ìˆ˜\n",
    "    completeness_factors = []\n",
    "    completeness_factors.append(100 if validation['has_erd_tables'] else 0)\n",
    "    completeness_factors.append(100 if validation['has_erd_relationships'] else 0)\n",
    "    completeness_factors.append(100 if validation['table_count'] >= 3 else validation['table_count'] * 33.3)\n",
    "    completeness_factors.append(100 if validation['primary_key_count'] >= validation['table_count'] else \n",
    "                               (validation['primary_key_count'] / max(validation['table_count'], 1)) * 100)\n",
    "    \n",
    "    quality_metrics['completeness_score'] = sum(completeness_factors) / len(completeness_factors)\n",
    "    \n",
    "    # 2. ë³µì¡ë„ ì ìˆ˜ (ì ì ˆí•œ ë³µì¡ë„ì¸ê°€)\n",
    "    table_count = validation['table_count']\n",
    "    relationship_count = validation['relationship_count']\n",
    "    \n",
    "    # 3-10ê°œ í…Œì´ë¸”ì´ ì ì ˆ, ê´€ê³„ëŠ” í…Œì´ë¸” ìˆ˜ì™€ ë¹„ìŠ·í•˜ê±°ë‚˜ ì ê²Œ\n",
    "    if 3 <= table_count <= 10:\n",
    "        complexity_table_score = 100\n",
    "    elif table_count < 3:\n",
    "        complexity_table_score = table_count * 33.3\n",
    "    else:\n",
    "        complexity_table_score = max(0, 100 - (table_count - 10) * 5)\n",
    "    \n",
    "    if relationship_count <= table_count:\n",
    "        complexity_rel_score = 100\n",
    "    else:\n",
    "        complexity_rel_score = max(0, 100 - (relationship_count - table_count) * 10)\n",
    "    \n",
    "    quality_metrics['complexity_score'] = (complexity_table_score + complexity_rel_score) / 2\n",
    "    \n",
    "    # 3. ì •ê·œí™” ì ìˆ˜\n",
    "    normalization_factors = []\n",
    "    \n",
    "    # ê¸°ë³¸í‚¤ ì¡´ì¬ìœ¨\n",
    "    if validation['table_count'] > 0:\n",
    "        pk_ratio = validation['primary_key_count'] / validation['table_count']\n",
    "        normalization_factors.append(min(pk_ratio * 100, 100))\n",
    "    \n",
    "    # ì™¸ë˜í‚¤ í™œìš©ë„\n",
    "    if validation['relationship_count'] > 0:\n",
    "        fk_ratio = validation['foreign_key_count'] / validation['relationship_count']\n",
    "        normalization_factors.append(min(fk_ratio * 100, 100))\n",
    "    else:\n",
    "        normalization_factors.append(100)  # ê´€ê³„ê°€ ì—†ìœ¼ë©´ ë§Œì \n",
    "    \n",
    "    if normalization_factors:\n",
    "        quality_metrics['normalization_score'] = sum(normalization_factors) / len(normalization_factors)\n",
    "    \n",
    "    # 4. ì„¤ê³„ í’ˆì§ˆ ì¢…í•© ì ìˆ˜\n",
    "    quality_metrics['design_quality_score'] = (\n",
    "        quality_metrics['completeness_score'] * 0.4 +\n",
    "        quality_metrics['complexity_score'] * 0.3 +\n",
    "        quality_metrics['normalization_score'] * 0.3\n",
    "    )\n",
    "    \n",
    "    return quality_metrics\n",
    "\n",
    "# ========================================================================================\n",
    "# API í˜¸ì¶œ ë° ë©”ì¸ í‰ê°€ í•¨ìˆ˜\n",
    "# ========================================================================================\n",
    "\n",
    "def format_data_for_prompt(data):\n",
    "    \"\"\"ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì í•©í•œ í˜•íƒœë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    if isinstance(data, str):\n",
    "        return data\n",
    "    elif isinstance(data, (dict, list)):\n",
    "        return json.dumps(data, ensure_ascii=False, indent=2)\n",
    "    else:\n",
    "        return str(data)\n",
    "\n",
    "def openai_chat_completion(model, user_input, project_info):\n",
    "    \"\"\"OpenAI Chat Completion APIë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        formatted_project_info = format_data_for_prompt(project_info)\n",
    "        formatted_user_input = format_data_for_prompt(user_input)\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "í”„ë¡œì íŠ¸ ì •ë³´:\n",
    "{formatted_project_info}\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "{formatted_user_input}\n",
    "\n",
    "**í•„ìˆ˜ JSON í˜•ì‹:**\n",
    "{{\n",
    "  \"erd_tables\": [{{\n",
    "    \"name\": \"í…Œì´ë¸”ëª…\",\n",
    "    \"erd_columns\": [{{\n",
    "      \"name\": \"ì»¬ëŸ¼ëª…\",\n",
    "      \"data_type\": \"íƒ€ì…\",\n",
    "      \"is_primary_key\": true/false,\n",
    "      \"is_foreign_key\": true/false,\n",
    "      \"is_nullable\": true/false\n",
    "    }}]\n",
    "  }}],\n",
    "  \"erd_relationships\": [{{\n",
    "    \"from_table\": \"ì‹œì‘í…Œì´ë¸”\",\n",
    "    \"to_table\": \"ëí…Œì´ë¸”\",\n",
    "    \"relationship_type\": \"one-to-many\",\n",
    "    \"foreign_key\": \"ì™¸ë˜í‚¤ëª…\",\n",
    "    \"constraint_name\": \"ì œì•½ì¡°ê±´ëª…\"\n",
    "  }}]\n",
    "}}\n",
    "**í•µì‹¬ ê·œì¹™:**\n",
    "1. ê´€ê³„ì˜ ëª¨ë“  í…Œì´ë¸”ëª…ì´ erd_tablesì— ì¡´ì¬í•´ì•¼ í•¨\n",
    "2. ê´€ê³„ì˜ ëª¨ë“  foreign_keyê°€ í•´ë‹¹ í…Œì´ë¸” ì»¬ëŸ¼ì— ì¡´ì¬í•´ì•¼ í•¨\n",
    "3. ì™¸ë˜í‚¤ëŠ” is_foreign_key: true ì„¤ì •\n",
    "4. ìµœì†Œ 5ê°œ í…Œì´ë¸”, ë°±ìŠ¬ë˜ì‹œ ê¸ˆì§€, ìˆœìˆ˜ JSONë§Œ\n",
    "ìœ„ ê·œì¹™ì„ ì§€ì¼œ ì™„ì „í•œ ERDë¥¼ ìƒì„±í•˜ì„¸ìš”!\n",
    "\"\"\"}\n",
    "        ]\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API í˜¸ì¶œ ì˜¤ë¥˜ ({model}): {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def run_erd_specialized_evaluation():\n",
    "    \"\"\"ERD íŠ¹í™” 3ëª¨ë¸ ë¹„êµ í‰ê°€ ì‹¤í–‰\"\"\"\n",
    "    print(\"ğŸ¯ ERD íŠ¹í™” 3ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: êµ¬ì¡°ì  í’ˆì§ˆê³¼ ì •í™•ì„± ì¤‘ì‹¬ í‰ê°€\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 1. ë°ì´í„° ë¡œë“œ ë° ê²€ì¦\n",
    "    # ========================================================================================\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_FILE_PATH)\n",
    "        print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒ˜í”Œ\")\n",
    "        print(f\"ğŸ“‹ CSV ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    print(\"\\nğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "    for col in ['user_input', 'project_info', 'total_requirements', 'ERD_data']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: safe_parse_json(str(x))[0] if pd.notna(x) else {})\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 2. í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì„¤ì • (ë” ë§ì€ ìƒ˜í”Œë¡œ í™•ì¥)\n",
    "    # ========================================================================================\n",
    "    \n",
    "    test_samples = min(5, len(df))  # 20ê°œ ìƒ˜í”Œë¡œ í™•ì¥\n",
    "    test_df = df.head(test_samples).copy()\n",
    "    \n",
    "    print(f\"\\nğŸ”„ {test_samples}ê°œ ìƒ˜í”Œì— ëŒ€í•´ 3ê°œ ëª¨ë¸ ERD ìƒì„± ì‹œì‘...\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 3. 3ê°œ ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰\n",
    "    # ========================================================================================\n",
    "    \n",
    "    results = {\n",
    "        'finetuned': {'predictions': [], 'model_name': 'íŒŒì¸íŠœë‹_ëª¨ë¸'},\n",
    "        'mini': {'predictions': [], 'model_name': 'GPT-4o-mini'},\n",
    "        'gpt4o': {'predictions': [], 'model_name': 'GPT-4o'}\n",
    "    }\n",
    "    \n",
    "    models = [\n",
    "        (FINETUNED_MODEL, 'finetuned', 'ğŸ¯'),\n",
    "        (BASELINE_MINI_MODEL, 'mini', 'ğŸ¤–'),\n",
    "        (BASELINE_4O_MODEL, 'gpt4o', 'ğŸ”¥')\n",
    "    ]\n",
    "    \n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"ëª¨ë¸ ì¶”ë¡  ì§„í–‰\"):\n",
    "        user_input = row['user_input']\n",
    "        project_info = row['project_info']\n",
    "        \n",
    "        print(f\"\\nğŸ“ ìƒ˜í”Œ {idx+1} ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        for model_id, result_key, emoji in models:\n",
    "            print(f\"   {emoji} {results[result_key]['model_name']} ì¶”ë¡ ...\")\n",
    "            \n",
    "            prediction = openai_chat_completion(model_id, user_input, project_info)\n",
    "            results[result_key]['predictions'].append(prediction)\n",
    "            \n",
    "            time.sleep(0.5)  # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë°©ì§€\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 4. ERD íŠ¹í™” í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(\"\\nğŸ“Š ERD íŠ¹í™” í‰ê°€ ê²°ê³¼ ë¶„ì„\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    references = test_df['ERD_data'].tolist()\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for result_key, result_data in results.items():\n",
    "        model_name = result_data['model_name']\n",
    "        predictions = result_data['predictions']\n",
    "        \n",
    "        print(f\"\\nğŸ” {model_name} ë¶„ì„ ì¤‘...\")\n",
    "        \n",
    "        # JSON íŒŒì‹± ì„±ê³µë¥  ê³„ì‚°\n",
    "        parsed_predictions = []\n",
    "        json_success_count = 0\n",
    "        \n",
    "        for pred in predictions:\n",
    "            parsed_pred, is_valid = safe_parse_json(pred)\n",
    "            parsed_predictions.append(parsed_pred)\n",
    "            if is_valid:\n",
    "                json_success_count += 1\n",
    "        \n",
    "        json_success_rate = (json_success_count / len(predictions)) * 100\n",
    "        \n",
    "        # ERD êµ¬ì¡° ê²€ì¦\n",
    "        structure_validations = [validate_erd_structure(pred) for pred in parsed_predictions]\n",
    "        \n",
    "        # ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ê³„ì‚°\n",
    "        consistency_scores = [calculate_schema_consistency(pred) for pred in parsed_predictions]\n",
    "        \n",
    "        # ERD í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\n",
    "        quality_scores = [calculate_erd_quality_score(pred) for pred in parsed_predictions]\n",
    "        \n",
    "        # ì°¸ì¡° ë°ì´í„°ì™€ ë¹„êµ\n",
    "        comparison_scores = []\n",
    "        for pred, ref in zip(parsed_predictions, references):\n",
    "            if isinstance(ref, dict) and ref:\n",
    "                comparison = compare_erd_structures(pred, ref)\n",
    "                comparison_scores.append(comparison)\n",
    "            else:\n",
    "                comparison_scores.append({\n",
    "                    'table_name_similarity': 0.0,\n",
    "                    'column_structure_similarity': 0.0,\n",
    "                    'relationship_similarity': 0.0,\n",
    "                    'overall_structure_similarity': 0.0\n",
    "                })\n",
    "        \n",
    "        # í‰ê·  ê³„ì‚°\n",
    "        avg_metrics = {\n",
    "            'JSON_íŒŒì‹±_ì„±ê³µë¥ (%)': json_success_rate,\n",
    "            'í‰ê· _í…Œì´ë¸”_ìˆ˜': np.mean([v['table_count'] for v in structure_validations]),\n",
    "            'í‰ê· _ê´€ê³„_ìˆ˜': np.mean([v['relationship_count'] for v in structure_validations]),\n",
    "            'í‰ê· _ì»¬ëŸ¼_ìˆ˜': np.mean([v['column_count'] for v in structure_validations]),\n",
    "            'ì™¸ë˜í‚¤_ì¼ê´€ì„±(%)': np.mean([c['foreign_key_consistency'] for c in consistency_scores]),\n",
    "            'ê´€ê³„_ì¼ê´€ì„±(%)': np.mean([c['relationship_consistency'] for c in consistency_scores]),\n",
    "            'ë„¤ì´ë°_ì¼ê´€ì„±(%)': np.mean([c['naming_consistency'] for c in consistency_scores]),\n",
    "            'ì™„ì„±ë„_ì ìˆ˜(%)': np.mean([q['completeness_score'] for q in quality_scores]),\n",
    "            'ë³µì¡ë„_ì ìˆ˜(%)': np.mean([q['complexity_score'] for q in quality_scores]),\n",
    "            'ì •ê·œí™”_ì ìˆ˜(%)': np.mean([q['normalization_score'] for q in quality_scores]),\n",
    "            'ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%)': np.mean([q['design_quality_score'] for q in quality_scores]),\n",
    "            'í…Œì´ë¸”ëª…_ì¼ì¹˜ë„(%)': np.mean([c['table_name_similarity'] for c in comparison_scores]),\n",
    "            'ì»¬ëŸ¼êµ¬ì¡°_ì¼ì¹˜ë„(%)': np.mean([c['column_structure_similarity'] for c in comparison_scores]),\n",
    "            'ê´€ê³„êµ¬ì¡°_ì¼ì¹˜ë„(%)': np.mean([c['relationship_similarity'] for c in comparison_scores]),\n",
    "            'ì „ì²´êµ¬ì¡°_ì¼ì¹˜ë„(%)': np.mean([c['overall_structure_similarity'] for c in comparison_scores])\n",
    "        }\n",
    "        \n",
    "        evaluation_results[model_name] = avg_metrics\n",
    "        \n",
    "        print(f\"   JSON íŒŒì‹± ì„±ê³µë¥ : {json_success_rate:.1f}%\")\n",
    "        print(f\"   í‰ê·  í…Œì´ë¸” ìˆ˜: {avg_metrics['í‰ê· _í…Œì´ë¸”_ìˆ˜']:.1f}\")\n",
    "        print(f\"   ì„¤ê³„ í’ˆì§ˆ ì ìˆ˜: {avg_metrics['ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%)']:.1f}%\")\n",
    "        print(f\"   ì „ì²´ êµ¬ì¡° ì¼ì¹˜ë„: {avg_metrics['ì „ì²´êµ¬ì¡°_ì¼ì¹˜ë„(%)']:.1f}%\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 5. ì¢…í•© ë¹„êµ ë¶„ì„\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ ERD íŠ¹í™” ì„±ëŠ¥ ë¹„êµ ë¶„ì„\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # í•µì‹¬ ë©”íŠ¸ë¦­ë“¤\n",
    "    key_metrics = [\n",
    "        'JSON_íŒŒì‹±_ì„±ê³µë¥ (%)',\n",
    "        'ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%)',\n",
    "        'ì „ì²´êµ¬ì¡°_ì¼ì¹˜ë„(%)',\n",
    "        'ê´€ê³„_ì¼ê´€ì„±(%)',\n",
    "        'ì™„ì„±ë„_ì ìˆ˜(%)'\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'ë©”íŠ¸ë¦­':<20} {'íŒŒì¸íŠœë‹':<12} {'4o-mini':<12} {'GPT-4o':<12} {'vs mini':<12} {'vs 4o':<12}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    ft_results = evaluation_results['íŒŒì¸íŠœë‹_ëª¨ë¸']\n",
    "    mini_results = evaluation_results['GPT-4o-mini']\n",
    "    gpt4o_results = evaluation_results['GPT-4o']\n",
    "    \n",
    "    for metric in key_metrics:\n",
    "        ft_score = ft_results[metric]\n",
    "        mini_score = mini_results[metric]\n",
    "        gpt4o_score = gpt4o_results[metric]\n",
    "        \n",
    "        vs_mini = ft_score - mini_score\n",
    "        vs_4o = ft_score - gpt4o_score\n",
    "        \n",
    "        print(f\"{metric:<20} {ft_score:<12.1f} {mini_score:<12.1f} {gpt4o_score:<12.1f} {vs_mini:<+12.1f} {vs_4o:<+12.1f}\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 6. ì„¸ë¶€ ë¶„ì„ ê²°ê³¼\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ” ì„¸ë¶€ ERD í’ˆì§ˆ ë¶„ì„\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # êµ¬ì¡°ì  í’ˆì§ˆ ë¶„ì„\n",
    "    print(\"\\nğŸ“Š êµ¬ì¡°ì  í’ˆì§ˆ ë¶„ì„:\")\n",
    "    structure_metrics = ['í‰ê· _í…Œì´ë¸”_ìˆ˜', 'í‰ê· _ê´€ê³„_ìˆ˜', 'í‰ê· _ì»¬ëŸ¼_ìˆ˜']\n",
    "    \n",
    "    for metric in structure_metrics:\n",
    "        ft_val = ft_results[metric]\n",
    "        mini_val = mini_results[metric]\n",
    "        gpt4o_val = gpt4o_results[metric]\n",
    "        print(f\"  {metric}: íŒŒì¸íŠœë‹={ft_val:.1f}, 4o-mini={mini_val:.1f}, GPT-4o={gpt4o_val:.1f}\")\n",
    "    \n",
    "    # ì¼ê´€ì„± ë¶„ì„\n",
    "    print(\"\\nğŸ”— ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ë¶„ì„:\")\n",
    "    consistency_metrics = ['ì™¸ë˜í‚¤_ì¼ê´€ì„±(%)', 'ê´€ê³„_ì¼ê´€ì„±(%)', 'ë„¤ì´ë°_ì¼ê´€ì„±(%)']\n",
    "    \n",
    "    for metric in consistency_metrics:\n",
    "        ft_val = ft_results[metric]\n",
    "        mini_val = mini_results[metric]\n",
    "        gpt4o_val = gpt4o_results[metric]\n",
    "        print(f\"  {metric}: íŒŒì¸íŠœë‹={ft_val:.1f}%, 4o-mini={mini_val:.1f}%, GPT-4o={gpt4o_val:.1f}%\")\n",
    "    \n",
    "    # ì •í™•ì„± ë¶„ì„\n",
    "    print(\"\\nğŸ¯ êµ¬ì¡° ì •í™•ì„± ë¶„ì„:\")\n",
    "    accuracy_metrics = ['í…Œì´ë¸”ëª…_ì¼ì¹˜ë„(%)', 'ì»¬ëŸ¼êµ¬ì¡°_ì¼ì¹˜ë„(%)', 'ê´€ê³„êµ¬ì¡°_ì¼ì¹˜ë„(%)']\n",
    "    \n",
    "    for metric in accuracy_metrics:\n",
    "        ft_val = ft_results[metric]\n",
    "        mini_val = mini_results[metric]\n",
    "        gpt4o_val = gpt4o_results[metric]\n",
    "        print(f\"  {metric}: íŒŒì¸íŠœë‹={ft_val:.1f}%, 4o-mini={mini_val:.1f}%, GPT-4o={gpt4o_val:.1f}%\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 7. íŒŒì¸íŠœë‹ íš¨ê³¼ ë¶„ì„\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ¯ íŒŒì¸íŠœë‹ íš¨ê³¼ ì‹¬ì¸µ ë¶„ì„\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ë² ì´ìŠ¤ ëª¨ë¸ ëŒ€ë¹„ ê°œì„ ë„\n",
    "    print(\"ğŸ“ˆ ë² ì´ìŠ¤ ëª¨ë¸(GPT-4o-mini) ëŒ€ë¹„ íŒŒì¸íŠœë‹ ê°œì„ ë„:\")\n",
    "    mini_improvements = 0\n",
    "    total_improvement = 0\n",
    "    \n",
    "    for metric in key_metrics:\n",
    "        ft_score = ft_results[metric]\n",
    "        mini_score = mini_results[metric]\n",
    "        diff = ft_score - mini_score\n",
    "        improvement_rate = (diff / mini_score) * 100 if mini_score != 0 else 0\n",
    "        \n",
    "        print(f\"  {metric}: {diff:+.1f} ({improvement_rate:+.1f}%)\")\n",
    "        \n",
    "        if diff > 0:\n",
    "            mini_improvements += 1\n",
    "        total_improvement += improvement_rate\n",
    "    \n",
    "    avg_improvement = total_improvement / len(key_metrics)\n",
    "    \n",
    "    # í”Œë˜ê·¸ì‹­ ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥\n",
    "    print(f\"\\nğŸ”¥ í”Œë˜ê·¸ì‹­ ëª¨ë¸(GPT-4o) ëŒ€ë¹„ íŒŒì¸íŠœë‹ ì„±ëŠ¥:\")\n",
    "    gpt4o_wins = 0\n",
    "    \n",
    "    for metric in key_metrics:\n",
    "        ft_score = ft_results[metric]\n",
    "        gpt4o_score = gpt4o_results[metric]\n",
    "        diff = ft_score - gpt4o_score\n",
    "        \n",
    "        status = \"ğŸŸ¢ ìš°ìˆ˜\" if diff > 2 else \"ğŸŸ¡ ë™ë“±\" if abs(diff) <= 2 else \"ğŸ”´ ì—´ì„¸\"\n",
    "        print(f\"  {metric}: {diff:+.1f} ({status})\")\n",
    "        \n",
    "        if diff > 0:\n",
    "            gpt4o_wins += 1\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 8. ëª¨ë¸ë³„ ê°•ì  ë¶„ì„\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nâš¡ ëª¨ë¸ë³„ ê°•ì  ë¶„ì„\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ê° ëª¨ë¸ì´ ê°€ì¥ ìš°ìˆ˜í•œ ë©”íŠ¸ë¦­ ì°¾ê¸°\n",
    "    all_metrics = list(ft_results.keys())\n",
    "    model_strengths = {\n",
    "        'íŒŒì¸íŠœë‹_ëª¨ë¸': [],\n",
    "        'GPT-4o-mini': [],\n",
    "        'GPT-4o': []\n",
    "    }\n",
    "    \n",
    "    for metric in all_metrics:\n",
    "        scores = {\n",
    "            'íŒŒì¸íŠœë‹_ëª¨ë¸': ft_results[metric],\n",
    "            'GPT-4o-mini': mini_results[metric],\n",
    "            'GPT-4o': gpt4o_results[metric]\n",
    "        }\n",
    "        best_model = max(scores, key=scores.get)\n",
    "        model_strengths[best_model].append((metric, scores[best_model]))\n",
    "    \n",
    "    for model_name, strengths in model_strengths.items():\n",
    "        if strengths:\n",
    "            print(f\"\\nğŸ† {model_name} ìµœìš°ìˆ˜ ì˜ì—­:\")\n",
    "            for metric, score in strengths[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ\n",
    "                print(f\"  â€¢ {metric}: {score:.1f}\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 9. ì‹¤ìš©ì„± í‰ê°€\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ’¼ ì‹¤ìš©ì„± í‰ê°€\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # JSON ìƒì„± ì•ˆì •ì„± í‰ê°€\n",
    "    json_success_rates = {\n",
    "        'íŒŒì¸íŠœë‹': ft_results['JSON_íŒŒì‹±_ì„±ê³µë¥ (%)'],\n",
    "        '4o-mini': mini_results['JSON_íŒŒì‹±_ì„±ê³µë¥ (%)'],\n",
    "        'GPT-4o': gpt4o_results['JSON_íŒŒì‹±_ì„±ê³µë¥ (%)']\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ”§ JSON ìƒì„± ì•ˆì •ì„±:\")\n",
    "    for model, rate in json_success_rates.items():\n",
    "        stability = \"ğŸŸ¢ ë§¤ìš°ì•ˆì •\" if rate >= 90 else \"ğŸŸ¡ ë³´í†µ\" if rate >= 70 else \"ğŸ”´ ë¶ˆì•ˆì •\"\n",
    "        print(f\"  {model}: {rate:.1f}% ({stability})\")\n",
    "    \n",
    "    # ERD ì„¤ê³„ í’ˆì§ˆ ì¢…í•©\n",
    "    design_quality = {\n",
    "        'íŒŒì¸íŠœë‹': ft_results['ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%)'],\n",
    "        '4o-mini': mini_results['ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%)'],\n",
    "        'GPT-4o': gpt4o_results['ì„¤ê³„í’ˆì§ˆ_ì ìˆ˜(%)']\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ¨ ERD ì„¤ê³„ í’ˆì§ˆ:\")\n",
    "    for model, quality in design_quality.items():\n",
    "        grade = \"ğŸŸ¢ ìš°ìˆ˜\" if quality >= 80 else \"ğŸŸ¡ ì–‘í˜¸\" if quality >= 60 else \"ğŸ”´ ê°œì„ í•„ìš”\"\n",
    "        print(f\"  {model}: {quality:.1f}% ({grade})\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 10. ìµœì¢… ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\n",
    "    # ========================================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ† ìµœì¢… ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # íŒŒì¸íŠœë‹ íš¨ê³¼ íŒì •\n",
    "    if mini_improvements >= 3 and avg_improvement > 5:\n",
    "        ft_verdict = \"ğŸŸ¢ íŒŒì¸íŠœë‹ ëŒ€ì„±ê³µ! ë² ì´ìŠ¤ ëª¨ë¸ ëŒ€ë¹„ ëª…í™•í•œ ê°œì„ \"\n",
    "    elif mini_improvements >= 2:\n",
    "        ft_verdict = \"ğŸŸ¡ íŒŒì¸íŠœë‹ íš¨ê³¼ ìˆìŒ. ì¼ë¶€ ì˜ì—­ì—ì„œ ê°œì„ \"\n",
    "    else:\n",
    "        ft_verdict = \"ğŸ”´ íŒŒì¸íŠœë‹ íš¨ê³¼ ì œí•œì . ì¶”ê°€ ìµœì í™” í•„ìš”\"\n",
    "    \n",
    "    print(f\"ğŸ“Š íŒŒì¸íŠœë‹ íš¨ê³¼: {ft_verdict}\")\n",
    "    print(f\"   â€¢ {mini_improvements}/{len(key_metrics)} ì£¼ìš” ë©”íŠ¸ë¦­ì—ì„œ ê°œì„ \")\n",
    "    print(f\"   â€¢ í‰ê·  ê°œì„ ìœ¨: {avg_improvement:+.1f}%\")\n",
    "    \n",
    "    # GPT-4o ëŒ€ë¹„ ì„±ëŠ¥\n",
    "    if gpt4o_wins >= 3:\n",
    "        gpt4o_verdict = \"ğŸ”¥ í”Œë˜ê·¸ì‹­ ëª¨ë¸ì„ ëŠ¥ê°€í•˜ëŠ” ë†€ë¼ìš´ ì„±ê³¼!\"\n",
    "    elif gpt4o_wins >= 2:\n",
    "        gpt4o_verdict = \"âš¡ í”Œë˜ê·¸ì‹­ ëª¨ë¸ê³¼ ê²½ìŸ ê°€ëŠ¥í•œ ìˆ˜ì¤€\"\n",
    "    else:\n",
    "        gpt4o_verdict = \"ğŸ“ˆ í”Œë˜ê·¸ì‹­ ëª¨ë¸ ëŒ€ë¹„ ê°œì„  ì—¬ì§€ ì¡´ì¬\"\n",
    "    \n",
    "    print(f\"\\nğŸ¯ GPT-4o ëŒ€ë¹„: {gpt4o_verdict}\")\n",
    "    print(f\"   â€¢ {gpt4o_wins}/{len(key_metrics)} ì£¼ìš” ë©”íŠ¸ë¦­ì—ì„œ ìš°ì„¸\")\n",
    "    \n",
    "    # ì‹¤ìš©ì  ê¶Œì¥ì‚¬í•­\n",
    "    print(f\"\\nğŸ’¡ ì‹¤ìš©ì  ê¶Œì¥ì‚¬í•­:\")\n",
    "    \n",
    "    # ê°€ì¥ ìš°ìˆ˜í•œ ëª¨ë¸ ì„ íƒ\n",
    "    overall_scores = {\n",
    "        'íŒŒì¸íŠœë‹': np.mean([ft_results[m] for m in key_metrics]),\n",
    "        '4o-mini': np.mean([mini_results[m] for m in key_metrics]),\n",
    "        'GPT-4o': np.mean([gpt4o_results[m] for m in key_metrics])\n",
    "    }\n",
    "    \n",
    "    best_model = max(overall_scores, key=overall_scores.get)\n",
    "    \n",
    "    if best_model == 'íŒŒì¸íŠœë‹':\n",
    "        print(\"  ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸ ì‚¬ìš© ê¶Œì¥:\")\n",
    "        print(\"    - ERD íŠ¹í™” ì‘ì—…ì— ìµœì í™”ë¨\")\n",
    "        print(\"    - ë¹„ìš© íš¨ìœ¨ì  (GPT-4o ëŒ€ë¹„ ~90% ì ˆì•½)\")\n",
    "        print(\"    - ë¹ ë¥¸ ì‘ë‹µ ì†ë„\")\n",
    "    elif best_model == 'GPT-4o':\n",
    "        print(\"  ğŸ”¥ GPT-4o ì‚¬ìš© ê¶Œì¥:\")\n",
    "        print(\"    - ìµœê³  í’ˆì§ˆì˜ ERD ì„¤ê³„\")\n",
    "        print(\"    - ë³µì¡í•œ ìš”êµ¬ì‚¬í•­ ì²˜ë¦¬ ìš°ìˆ˜\")\n",
    "        print(\"    - ë†’ì€ ì¼ê´€ì„±\")\n",
    "    else:\n",
    "        print(\"  ğŸ¤– GPT-4o-mini ì‚¬ìš© ê¶Œì¥:\")\n",
    "        print(\"    - ê· í˜•ì¡íŒ ì„±ëŠ¥\")\n",
    "        print(\"    - ì ë‹¹í•œ ë¹„ìš©\")\n",
    "        print(\"    - ì•ˆì •ì ì¸ ê²°ê³¼\")\n",
    "    \n",
    "    # ë¹„ìš© ëŒ€ë¹„ ì„±ëŠ¥ ë¶„ì„\n",
    "    print(f\"\\nğŸ’° ë¹„ìš© ëŒ€ë¹„ ì„±ëŠ¥ ë¶„ì„:\")\n",
    "    print(f\"  íŒŒì¸íŠœë‹ ëª¨ë¸: ì„±ëŠ¥ {overall_scores['íŒŒì¸íŠœë‹']:.1f}, ë¹„ìš© â­\")\n",
    "    print(f\"  GPT-4o-mini: ì„±ëŠ¥ {overall_scores['4o-mini']:.1f}, ë¹„ìš© â­â­\")\n",
    "    print(f\"  GPT-4o: ì„±ëŠ¥ {overall_scores['GPT-4o']:.1f}, ë¹„ìš© â­â­â­â­â­\")\n",
    "    \n",
    "    roi_scores = {\n",
    "        'íŒŒì¸íŠœë‹': overall_scores['íŒŒì¸íŠœë‹'] * 5,  # ë¹„ìš©ì´ 1/5ì´ë¯€ë¡œ 5ë°° ê°€ì¤‘\n",
    "        '4o-mini': overall_scores['4o-mini'] * 2,   # ë¹„ìš©ì´ 1/2ì´ë¯€ë¡œ 2ë°° ê°€ì¤‘\n",
    "        'GPT-4o': overall_scores['GPT-4o']          # ê¸°ì¤€\n",
    "    }\n",
    "    \n",
    "    best_roi = max(roi_scores, key=roi_scores.get)\n",
    "    print(f\"  ğŸ’ ìµœê³  ROI: {best_roi} (ë¹„ìš©íš¨ìœ¨ì ìˆ˜: {roi_scores[best_roi]:.1f})\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 11. ê²°ê³¼ ì €ì¥\n",
    "    # ========================================================================================\n",
    "    \n",
    "    try:\n",
    "        # ìƒì„¸ ê²°ê³¼ ì €ì¥\n",
    "        detailed_results = {\n",
    "            'evaluation_summary': {\n",
    "                'test_samples': test_samples,\n",
    "                'evaluation_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                'key_findings': {\n",
    "                    'finetuning_improvements': mini_improvements,\n",
    "                    'avg_improvement_rate': avg_improvement,\n",
    "                    'gpt4o_competitive_metrics': gpt4o_wins,\n",
    "                    'best_overall_model': best_model,\n",
    "                    'best_roi_model': best_roi\n",
    "                }\n",
    "            },\n",
    "            'detailed_metrics': evaluation_results,\n",
    "            'model_strengths': model_strengths\n",
    "        }\n",
    "        \n",
    "        with open(\"ERDíŠ¹í™”_3ëª¨ë¸_ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(detailed_results, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ ìƒì„¸ ê²°ê³¼ê°€ 'ERDíŠ¹í™”_3ëª¨ë¸_ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥\n",
    "        summary_report = f\"\"\"\n",
    "ERD íŠ¹í™” 3ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ìš”ì•½ ë¦¬í¬íŠ¸\n",
    "=================================\n",
    "\n",
    "ğŸ“Š í…ŒìŠ¤íŠ¸ ê°œìš”:\n",
    "- ìƒ˜í”Œ ìˆ˜: {test_samples}ê°œ\n",
    "- í‰ê°€ ì¼ì‹œ: {time.strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "- í‰ê°€ ë°©ì‹: ERD êµ¬ì¡°ì  í’ˆì§ˆ ì¤‘ì‹¬\n",
    "\n",
    "ğŸ† ì£¼ìš” ê²°ê³¼:\n",
    "- íŒŒì¸íŠœë‹ íš¨ê³¼: {mini_improvements}/{len(key_metrics)} ë©”íŠ¸ë¦­ ê°œì„  (í‰ê·  {avg_improvement:+.1f}%)\n",
    "- GPT-4o ëŒ€ë¹„: {gpt4o_wins}/{len(key_metrics)} ë©”íŠ¸ë¦­ ìš°ì„¸\n",
    "- ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model}\n",
    "- ìµœê³  ROI ëª¨ë¸: {best_roi}\n",
    "\n",
    "ğŸ“ˆ í•µì‹¬ ë©”íŠ¸ë¦­ ë¹„êµ:\n",
    "\"\"\"\n",
    "        \n",
    "        for metric in key_metrics:\n",
    "            ft_score = ft_results[metric]\n",
    "            mini_score = mini_results[metric]\n",
    "            gpt4o_score = gpt4o_results[metric]\n",
    "            summary_report += f\"- {metric}: íŒŒì¸íŠœë‹={ft_score:.1f}, 4o-mini={mini_score:.1f}, GPT-4o={gpt4o_score:.1f}\\n\"\n",
    "        \n",
    "        summary_report += f\"\"\"\n",
    "ğŸ’¡ ê¶Œì¥ì‚¬í•­:\n",
    "- {ft_verdict}\n",
    "- {gpt4o_verdict}\n",
    "- ë¹„ìš© íš¨ìœ¨ì„±: {best_roi} ëª¨ë¸ ê¶Œì¥\n",
    "\n",
    "ìì„¸í•œ ë¶„ì„ ê²°ê³¼ëŠ” 'ERDíŠ¹í™”_3ëª¨ë¸_ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json' íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "        \n",
    "        with open(\"ERDíŠ¹í™”_ì„±ëŠ¥ë¹„êµ_ìš”ì•½.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(summary_report)\n",
    "        \n",
    "        print(f\"ğŸ“„ ìš”ì•½ ë¦¬í¬íŠ¸ê°€ 'ERDíŠ¹í™”_ì„±ëŠ¥ë¹„êµ_ìš”ì•½.txt' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ========================================================================================\n",
    "# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„\n",
    "# ========================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"ğŸš€ ERD íŠ¹í™” 3ëª¨ë¸ ì„±ëŠ¥ ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {CSV_FILE_PATH}\")\n",
    "    print(f\"ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸: {FINETUNED_MODEL}\")\n",
    "    print(f\"ğŸ¤– GPT-4o-mini: {BASELINE_MINI_MODEL}\")\n",
    "    print(f\"ğŸ”¥ GPT-4o: {BASELINE_4O_MODEL}\")\n",
    "    print(f\"ğŸŒ¡ï¸ ì˜¨ë„ ì„¤ì •: {TEMPERATURE}\")\n",
    "    print(f\"ğŸ“Š í‰ê°€ ë°©ì‹: ERD êµ¬ì¡°ì  í’ˆì§ˆ ë° ì •í™•ì„± ì¤‘ì‹¬\")\n",
    "    \n",
    "    run_erd_specialized_evaluation()\n",
    "    \n",
    "    print(\"\\nâœ… ERD íŠ¹í™” 3ëª¨ë¸ ì„±ëŠ¥ ë¹„êµê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ“‹ ê²°ê³¼ íŒŒì¼:\")\n",
    "    print(\"   â€¢ ERDíŠ¹í™”_3ëª¨ë¸_ì„±ëŠ¥ë¹„êµ_ê²°ê³¼.json (ìƒì„¸ ê²°ê³¼)\")\n",
    "    print(\"   â€¢ ERDíŠ¹í™”_ì„±ëŠ¥ë¹„êµ_ìš”ì•½.txt (ìš”ì•½ ë¦¬í¬íŠ¸)\")\n",
    "    print(\"\\nğŸ¯ ì´ì œ ERD ì„¤ê³„ì— ìµœì í™”ëœ í‰ê°€ë¡œ ì •í™•í•œ ëª¨ë¸ ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bab238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
