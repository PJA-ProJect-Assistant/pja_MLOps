{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7669df",
   "metadata": {},
   "source": [
    "# 4740 checkpoint 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cdd776a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cb795308704f3d8392395b4efda962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문:\n",
      "카페 등 자영업자를 위한 음악 취향 분석 플랫폼. 매장 분위기, 타겟 고객, 공간 콘셉트를 기반으로 적절한 배경음악을 AI가 자동 추천하며, 멜로디·비트 중심의 음악 필터링 기능도 제공. 단순 음악 추천을 넘어 인테리어 콘셉트, 세무·운영 등 자영업 전반에 대한 AI 컨설팅 기능도 포함해 웹/앱 형태로 서비스화. 주요 타겟층을 명확히 정의해 특화된 솔루션 제공이 필요하며, 현재는 콘셉트 구체화 및 서비스 방향 정립이 과제로 남아 있음.\n",
      "정답:\n",
      "**프로젝트 상세 정보:**\n",
      "{'project_summary': {'title': '음악 취향 분석 플랫폼', 'category': '웹/모바일 애플리케이션', 'target_users': ['자영업자', '카페 운영자', '소매점 운영자'], 'main_purpose': '매장 분위기와 타겟 고객에 맞는 적절한 배경음악 추천 및 AI 기반 컨설팅 제공', 'key_features': [{'feature': 'AI 음악 추천', 'description': '매장 분위기, 타겟 고객, 공간 콘셉트를 기반으로 한 자동 음악 추천'}, {'feature': '음악 필터링', 'description': '멜로디 및 비트 중심의 음악 필터링 기능'}, {'feature': 'AI 컨설팅', 'description': '인테리어 콘셉트, 세무 및 운영에 대한 AI 기반 컨설팅 기능'}], 'core_technologies': [{'category': 'Frontend', 'technologies': ['React', 'Vue.js', 'Tailwind CSS']}, {'category': 'Backend', 'technologies': ['Node.js', 'Python', 'Django']}, {'category': 'Database', 'technologies': ['MongoDB', 'PostgreSQL']}, {'category': 'AI', 'technologies': ['TensorFlow', 'PyTorch']}], 'problem_solving': {'current_problem': '자영업자들이 매장에 적합한 음악을 찾기 어려움', 'solution_approach': 'AI를 활용한 맞춤형 음악 추천 및 전반적인 운영 컨설팅 제공', 'expected_benefits': ['매장 분위기 개선', '고객 만족도 향상', '운영 효율성 증대']}, 'special_features': ['AI 기반 음악 추천 시스템', '인테리어 및 운영 관련 AI 컨설팅', '사용자 맞춤형 솔루션 제공'], 'business_model': {'type': 'SaaS', 'revenue_streams': ['월 구독료', '프리미엄 기능', '컨설팅 서비스'], 'target_market': '자영업자 및 소규모 매장'}, 'scalability': {'user_capacity': '최대 5만명 동시 접속', 'expansion_plan': '다양한 업종으로 서비스 확장', 'integration_capability': '타사 음악 스트리밍 서비스와의 연동'}, 'development_timeline': {'estimated_duration': '4개월', 'key_milestones': [{'phase': '기획 및 설계', 'duration': '1개월'}, {'phase': 'MVP 개발', 'duration': '2개월'}, {'phase': '테스트 및 배포', 'duration': '1개월'}]}, 'success_metrics': ['사용자 증가율', '음악 추천 정확도', '고객 만족도', '서비스 이용률'], 'challenges_and_risks': [{'challenge': 'AI 추천 시스템의 정확성', 'mitigation': '지속적인 데이터 학습 및 피드백 시스템 구축'}, {'challenge': '시장 경쟁', 'mitigation': '특화된 솔루션과 사용자 맞춤형 서비스 제공'}]}}\n",
      "\n",
      "**관계 데이터:**\n",
      "[{'from': 'Business', 'to': 'MusicRecommendation', 'type': 'one-to-many', 'foreign_key': 'business_id', 'constraint_name': 'fk_music_recommendation_business'}, {'from': 'Business', 'to': 'ConsultingService', 'type': 'one-to-many', 'foreign_key': 'business_id', 'constraint_name': 'fk_consulting_service_business'}]\n",
      "\n",
      "**ERD 데이터:**\n",
      "[{'name': 'Business', 'attributes': [{'name': 'business_id', 'data_type': 'INTEGER', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'name', 'data_type': 'VARCHAR(100)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'location', 'data_type': 'VARCHAR(255)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': True}, {'name': 'target_customer', 'data_type': 'VARCHAR(100)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': True}, {'name': 'concept', 'data_type': 'VARCHAR(255)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': True}]}, {'name': 'MusicRecommendation', 'attributes': [{'name': 'recommendation_id', 'data_type': 'INTEGER', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'business_id', 'data_type': 'INTEGER', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}, {'name': 'music_genre', 'data_type': 'VARCHAR(100)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': True}, {'name': 'melody_filter', 'data_type': 'BOOLEAN', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': True}, {'name': 'beat_filter', 'data_type': 'BOOLEAN', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': True}]}, {'name': 'ConsultingService', 'attributes': [{'name': 'service_id', 'data_type': 'INTEGER', 'is_primary_key': True, 'is_foreign_key': False, 'is_nullable': False}, {'name': 'business_id', 'data_type': 'INTEGER', 'is_primary_key': False, 'is_foreign_key': True, 'is_nullable': False}, {'name': 'service_type', 'data_type': 'VARCHAR(100)', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': True}, {'name': 'description', 'data_type': 'TEXT', 'is_primary_key': False, 'is_foreign_key': False, 'is_nullable': True}]}]\n",
      "\n",
      "**API 명세 데이터:**\n",
      "{'api_specification': {'openapi': '3.0.0', 'info': {'title': 'Music Recommendation API for Small Businesses', 'version': '1.0.0', 'description': '자영업자를 위한 음악 취향 분석 및 추천 API'}, 'servers': [{'url': 'https://api.example.com/v1', 'description': 'Production server'}], 'paths': {'/recommendations': {'post': {'summary': '음악 추천', 'description': '매장 분위기, 타겟 고객, 공간 콘셉트를 기반으로 적절한 배경음악을 추천합니다.', 'tags': ['Recommendations'], 'requestBody': {'required': True, 'content': {'application/json': {'schema': {'type': 'object', 'required': ['atmosphere', 'targetCustomer', 'concept'], 'properties': {'atmosphere': {'type': 'string', 'example': '편안한'}, 'targetCustomer': {'type': 'string', 'example': '젊은층'}, 'concept': {'type': 'string', 'example': '모던 인테리어'}}}}}, 'responses': {'200': {'description': '음악 추천 성공', 'content': {'application/json': {'schema': {'type': 'object', 'properties': {'status': {'type': 'string', 'example': 'success'}, 'data': {'type': 'array', 'items': {'$ref': '#/components/schemas/Song'}}}}}}}, '400': {'description': '잘못된 요청', 'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Error'}}}}}}}}, '/filters': {'post': {'summary': '음악 필터링', 'description': '멜로디 및 비트 중심으로 음악을 필터링합니다.', 'tags': ['Filters'], 'requestBody': {'required': True, 'content': {'application/json': {'schema': {'type': 'object', 'required': ['melody', 'beat'], 'properties': {'melody': {'type': 'string', 'example': '부드러운'}, 'beat': {'type': 'string', 'example': '빠른'}}}}}, 'responses': {'200': {'description': '음악 필터링 성공', 'content': {'application/json': {'schema': {'type': 'object', 'properties': {'status': {'type': 'string', 'example': 'success'}, 'data': {'type': 'array', 'items': {'$ref': '#/components/schemas/Song'}}}}}}}, '400': {'description': '잘못된 요청', 'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Error'}}}}}}}}, '/consulting': {'post': {'summary': 'AI 컨설팅 요청', 'description': '인테리어 콘셉트, 세무 및 운영에 대한 AI 컨설팅을 요청합니다.', 'tags': ['Consulting'], 'requestBody': {'required': True, 'content': {'application/json': {'schema': {'type': 'object', 'required': ['businessType', 'concerns'], 'properties': {'businessType': {'type': 'string', 'example': '카페'}, 'concerns': {'type': 'string', 'example': '세무 관리'}}}}}, 'responses': {'200': {'description': '컨설팅 요청 성공', 'content': {'application/json': {'schema': {'type': 'object', 'properties': {'status': {'type': 'string', 'example': 'success'}, 'advice': {'type': 'string', 'example': '세무 관리에 대한 조언을 드립니다.'}}}}}}, '400': {'description': '잘못된 요청', 'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Error'}}}}}}}}}, 'components': {'schemas': {'Song': {'type': 'object', 'properties': {'title': {'type': 'string', 'example': 'Chill Vibes'}, 'artist': {'type': 'string', 'example': 'DJ Chill'}, 'genre': {'type': 'string', 'example': 'Chillout'}, 'duration': {'type': 'string', 'example': '3:45'}}}, 'Error': {'type': 'object', 'properties': {'status': {'type': 'string', 'example': 'error'}, 'message': {'type': 'string', 'example': '오류가 발생했습니다'}, 'code': {'type': 'string', 'example': 'VALIDATION_ERROR'}}}}}}}\n",
      "생성:\n",
      "2017년 AI 어시스턴트입니다. 사용자가 질문이나 아이디어를 체계적으로 분석하고 구조화하여 구체적인 개발 계획을 제시하는 전문 AI입니다.\n",
      "\n",
      "## 주요 역할과 능력:\n",
      "\n",
      "### 1. 프로젝트 분석 전문가\n",
      "- 사용자가 제공하는 프로젝트 아이디어나 설명을 깊이 있게 분석합니다\n",
      "- 핵심 기능, 대상 사용자, 기술 스택, 문제 해결 방향 등을 체계적으로 파악합니다\n",
      "- 프로젝트의 문제 해결 방향과 기대 효과를 명확히 정의합니다\n",
      "\n",
      "### 2. 데이터베이스 설계 전문가\n",
      "- 프로젝트 요구사항을 바탕으로 최적화된 ERD(Entity Relationship Diagram)를 설계합니다\n",
      "- 테이블 간의 관계, 외래키 제약조건, 데이터 타입을 정확히 정의합니다\n",
      "- 확장성과 성능을 고려한 데이터베이스 구조를 제안합니다\n",
      "\n",
      "### 3. API 설계 전문가\n",
      "- RESTful API 원칙에 따라 체계적인 API 명세를 작성합니다\n",
      "- OpenAPI(Swagger) 3.0 표준을 준수하여 완전한 API 문서를 생성합니다\n",
      "- 각 엔드포인트별 요청/응답 스키마, 에러 처리, 인증 방식을 상세히 정의합니다\n",
      "\n",
      "## 응답 형식:\n",
      "모든 응답은 다음과 같은 구조화된 JSON 형태로 제공해야 합니다:\n",
      "\n",
      "1. **프로젝트 상세 정보**: 제목, 카테고리, 대상 사용자, 핵심 기능, 기술 스택, 문제 해결 방안 등을 포함한 종합 분석\n",
      "2. **관계 데이터**: 데이터베이스 테이블 간의 관계와 외래키 제약조건 정의\n",
      "3. **ERD 데이터**: 각 테이블의 속성, 데이터 타입, 키 정보를 포함한 완전한 스키마\n",
      "4. **API 명세 데이터**: OpenAPI 3.0 표준을 준수한 완전한 API 문서\n",
      "\n",
      "## 작업 원칙:\n",
      "- 사용자의 아이디어를 정확히 이해하고 누락된 부분은 논리적으로 추론하여 보완합니다\n",
      "- 실무에서 바로 활용 가능한 수준의 구체적이고 실용적인 결과물을 제공합니다\n",
      "- 최신 개발 트렌드와 베스트 프랙티스를 반영합니다\n",
      "- 확장성과 유지보수성을 고려한 설계를 우선시합니다\n",
      "- 불분명한 요구사항이 있을 경우 합리적인 가정을 통해 완전성 높은 결과물을 제안합니다\n",
      "\n",
      "## 작업 원칙 상세히:\n",
      "### 1. **사용자의 아이디어 정확히 이해하기**\n",
      "- 사용자의 설명을 깊이 있게 분석합니다\n",
      "- 핵심 기능과 대상 사용자를 명확히 정의합니다\n",
      "- 프로젝트의 문제 해결 방향과 기대 효과를 체계적으로 파악합니다\n",
      "\n",
      "### 2. **누락된 부분 보완하기**\n",
      "- 데이터베이스 테이블 간의 관계와 외래키 제약조건을 정확히 정의합니다\n",
      "- 각 테이블의 속성, 데이터 타입, 키 정보를 포함한 완전한 스키마를 생성합니다\n",
      "- 확장성과 성능을 고려한 데이터베이스 구조를 제안합니다\n",
      "\n",
      "### 3. **실무에서 바로 활용 가능한 수준의 구체적이다**\n",
      "- API 명세를 OpenAPI 3.0 표준을 준수하여 완전히 정의합니다\n",
      "- 각 엔드포인트별 요청/응답 스키마, 에러 처리, 인증 방식을 상세히 정의합니다\n",
      "- 테이블 간의 관계와 외래키 제약조건을 바탕으로 자동 생성 가능한 API 명세를 제공합니다\n",
      "\n",
      "### 4. **최신 개발 트렌드 반영**\n",
      "- RESTful API 원칙을 준수합니다\n",
      "- 각 엔드포인트별 에러 처리와 인증 방식을 체계적으로 정의합니다\n",
      "- OpenAPI 3.0 표준을 준수하여 완전한 API 문서를 생성합니다\n",
      "\n",
      "## 응답 형식 상세히:\n",
      "모든 응답은 다음과 같은 구조화된 JSON 형태로 제공해야 합니다:\n",
      "\n",
      "1. **프로젝트 상세 정보**: 제목, 카테고리, 대상 사용자, 핵심 기능, 기술 스택, 문제 해결 방안 등을 포함한 종합 분석\n",
      "2. **관계 데이터**: 데이터베이스 테이블 간의 관계와 외래키 제약조건 정의\n",
      "3. **ERD 데이터**: 각 테이블의 속성, 데이터 타입, 키 정보를 포함한 완전한 스키마\n",
      "4. **API 명세 데이터**: OpenAPI 3.0 표준을 준수한 완전한 API 문서\n",
      "\n",
      "## 작업 원칙:\n",
      "- **사용자의 아이디어 정확히 이해하기**: 사용자의 설명을 깊이 있게 분석합니다\n",
      "- **누락된 부분 보완하기**: 데이터베이스 테이블 간의 관계와 외래키 제약조건을 정확히 정의합니다\n",
      "- **실무에서 바로 활용 가능한 수준의 구체적이다**: API 명세를 OpenAPI 3.0 표준을 준수하여 완전히 정의합니다\n",
      "- **확장성과 유지보수성을 고려한 설계 우선시**: 데이터베이스 테이블 간의 관계와 외래키 제약조건을 바탕으로 확장성 있는 API 명세를 제안합니다\n",
      "- **최신 개발 트렌드 반영**: RESTful API 원칙을 준수합니다\n",
      "\n",
      "## 확장성과 유지보수성을 고려한 설계 원칙:\n",
      "- **테이블 간의 관계를 체계적으로 분석합니다**: 데이터베이스 테이블 간의 관계와 외래키 제약조건을 정확히 정의합니다\n",
      "- **확장성을 고려한 데이터 타입을 선택합니다**: 각 테이블의 속성에 대해 최적화된 데이터 타입을 선택합니다\n",
      "- **오픈API 3.0 표준을 준수합니다**: 확장성과 유지보수성을 고려한 API 명세를 생성합니다\n",
      "- **ERD를 바탕으로 자동 생성 가능한 API 명세를 제공합니다**: 테이블 간의 관계와 외래키 제약조건을 바탕으로 자동 생성 가능한 API 명세를 제공합니다\n",
      "- **API 각 엔드포인트별 요청/응답 스키마를 상세히 정의합니다**: OpenAPI 3.0 표준을 준수하여 각 엔드포인트별 요청/응답 스키마를 상세히 정의합니다\n",
      "- **에러 처리와 인증 방식을 체계적으로 정의합니다**: 각 엔드포인트별 에러 처리와 인증 방식을 체계적으로 정의합니다\n",
      "\n",
      "## 사용자가 제공하는 정보 구조화 원칙:\n",
      "- **title**: 프로젝트의 제목을 정확히 정의합니다\n",
      "- **categories**: 프로젝트를 정확히 분류하여 카테고리를 정의합니다\n",
      "- **target audience**: 대상 사용자를 상세히 분석합니다\n",
      "- **core features**: 핵심 기능을 체계적으로 파악합니다\n",
      "- **technology stack**: 사용 가능한 기술 스택를 정확히 정의합니다\n",
      "- **problem solving approach**: 문제 해결 방향과 기대 효과를 명확히 정의합니다\n",
      "\n",
      "## 확장성과 유지보수성을 고려한 API 설계 원칙:\n",
      "- **RESTful API 원칙 준수**: RESTful API 원칙을 준수하여 체계적인 API 명세를 작성합니다\n",
      "- **OpenAPI 3.0 표준 준수**: OpenAPI 3.0 표준을 준수하여 완전한 API 문서를 생성합니다\n",
      "- **each endpoint별 요청/응답 스키마 상세히 정의**: 각 엔드포인트별 요청/응답 스키마를 상세히 정의합니다\n",
      "- **에러 처리와 인증 방식 체계적으로 정의**: 각 엔드포인트별 에러 처리와 인증 방식을 체계적으로 정의합니다\n",
      "- **API 각 엔드포인트별 테스트 케이스 자동 생성**: OpenAPI 3.0 표준을 준수하여 각 엔드포인트별 테스트 케이스를 자동 생성합니다\n",
      "\n",
      "## 응답 형식:\n",
      "모든 응답은 다음과 같은 구조화된 JSON 형태로 제공해야 합니다:\n",
      "\n",
      "1. **프로젝트 상세 정보**: 제목, 카테고리, 대상 사용자, 핵심 기능, 기술 스택, 문제 해결 방안 등을 포함한 종합 분석\n",
      "2. **관계 데이터**: 데이터베이스 테이블 간의 관계와 외래키 제약조건 정의\n",
      "3. **ERD 데이터**: 각 테이블의 속성, 데이터 타입, 키 정보를 포함한 완전한 스키마\n",
      "4. **API 명세 데이터**: OpenAPI 3.0 표준을 준수한 완전한 API 문서\n",
      "\n",
      "## 작업 원칙:\n",
      "- **사용자의 아이디어 정확히 이해하기**: 사용자의 설명을 깊이 있게 분석합니다\n",
      "- **누락된 부분 보완하기**: 데이터베이스 테이블 간의 관계와 외래키 제약조건을 정확히 정의합니다\n",
      "- **실무에서 바로 활용 가능한 수준의 구체적이다**: API 명세를 OpenAPI 3.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch \n",
    "from random import randint\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "model_name = \"llama-3-korean-8b-qlora-high-perf/checkpoint-66\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "test_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=os.path.join(\"\", \"./test_dataset.json\"),\n",
    "    split=\"train\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=2000,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Load our test dataset\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39208b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Load our test dataset\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc79d75",
   "metadata": {},
   "source": [
    "## 최종모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0517e1a-6571-4929-9a53-1bb389f26747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Load our test dataset\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fcf32d-8ed1-4bcd-8517-7cb75794765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Load our test dataset\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a482327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Load our test dataset\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Load our test dataset\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ce3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Load our test dataset\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f93d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Load our test dataset\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166735f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93258c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18281af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = OpenAI(api_key=\"Your_OpenAI_API_KEY\")\n",
    "\n",
    "class Criterion(BaseModel):\n",
    "    score: int\n",
    "    explanation: str\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    relevance: Criterion\n",
    "    accuracy: Criterion\n",
    "    completeness: Criterion\n",
    "    clarity: Criterion\n",
    "    similarity: Criterion\n",
    "    average_score: float\n",
    "\n",
    "def evaluate_qa_model(question: str, reference_answer: str, model_answer: str) -> Evaluation:\n",
    "    prompt = f\"\"\"\n",
    "질문: {question}\n",
    "참조 답변: {reference_answer}\n",
    "모델 생성 답변: {model_answer}\n",
    "\n",
    "위의 질문에 대한 두 답변을 비교 평가해주세요. 다음 기준에 따라 1-10점 사이의 점수를 매겨주세요:\n",
    "1. 관련성: 모델의 답변이 질문과 얼마나 관련이 있는가?\n",
    "2. 정확성: 모델이 제공한 정보가 참조 답변과 비교하여 얼마나 정확한가?\n",
    "3. 완전성: 모델의 답변이 질문에 대해 얼마나 포괄적인가?\n",
    "4. 명확성: 모델의 답변이 얼마나 명확하고 이해하기 쉬운가?\n",
    "5. 유사성: 모델의 답변이 참조 답변과 얼마나 유사한가?\n",
    "\n",
    "각 기준에 대한 점수와 간단한 설명을 제공해주세요. 마지막으로 전체 평균 점수를 계산해주세요.\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",  # 또는 사용 가능한 최신 모델\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"귀하는 QA 모델 응답을 평가하는 임무를 맡은 AI 어시스턴트입니다.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=Evaluation\n",
    "    )\n",
    "\n",
    "    return completion\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"인공지능의 윤리적 고려사항은 무엇인가요?\"\n",
    "    reference_answer = \"인공지능의 주요 윤리적 고려사항에는 1) 프라이버시 보호: 개인 정보의 수집, 처리, 저장에 관한 문제, 2) 알고리즘 편향성 방지: 인종, 성별, 연령 등에 대한 차별 방지, 3) 투명성 확보: AI 의사결정 과정의 설명 가능성, 4) 책임성 명확화: AI 시스템의 오류나 해악에 대한 책임 소재, 5) 안전성과 보안: AI 시스템의 안전한 작동과 외부 공격으로부터의 보호, 6) 인간 통제: AI가 인간의 통제를 벗어나지 않도록 하는 것 등이 있습니다. 이러한 요소들은 AI 기술이 사회에 미치는 영향을 고려하여 신중하게 다루어져야 하며, 법적, 제도적 장치를 통해 관리되어야 합니다.\"\n",
    "    \n",
    "    model_answer = \"인공지능의 윤리적 고려사항에는 프라이버시 보호, 알고리즘 편향성 방지, 투명성 확보, 책임성 명확화 등이 있습니다. 이러한 요소들은 AI 기술이 사회에 미치는 영향을 고려하여 신중하게 다루어져야 합니다.\"\n",
    "\n",
    "    evaluation = evaluate_qa_model(question, reference_answer, model_answer)\n",
    "    print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c550ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.choices[0].message.parsed.relevance.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab7998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
